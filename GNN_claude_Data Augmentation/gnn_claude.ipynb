{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e7c2e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\DSS5104\\lib\\site-packages\\torch_geometric\\typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: [WinError 127] 找不到指定的程序。\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "d:\\Anaconda\\envs\\DSS5104\\lib\\site-packages\\torch_geometric\\typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: [WinError 127] 找不到指定的程序。\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
      "d:\\Anaconda\\envs\\DSS5104\\lib\\site-packages\\torch_geometric\\typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: [WinError 127] 找不到指定的程序。\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\DSS5104\\lib\\site-packages\\torch_geometric\\typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: [WinError 127] 找不到指定的程序。\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of molecules with missing SMILES: 0\n",
      "Using device: cpu\n",
      "Train set size: 20492\n",
      "Validation set size: 5072\n",
      "Test set size: 6460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting SMILES to graphs: 100%|██████████| 20492/20492 [00:08<00:00, 2529.28it/s]\n",
      "Converting SMILES to graphs: 100%|██████████| 5072/5072 [00:02<00:00, 2415.58it/s]\n",
      "Converting SMILES to graphs:   0%|          | 0/6460 [00:00<?, ?it/s][14:48:50] WARNING: not removing hydrogen atom without neighbors\n",
      "[14:48:50] WARNING: not removing hydrogen atom without neighbors\n",
      "[14:48:50] WARNING: not removing hydrogen atom without neighbors\n",
      "[14:48:50] WARNING: not removing hydrogen atom without neighbors\n",
      "Converting SMILES to graphs: 100%|██████████| 6460/6460 [00:02<00:00, 2544.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size after processing: 20492\n",
      "Validation dataset size after processing: 5072\n",
      "Test dataset size after processing: 6460\n",
      "Node feature dimension: 109\n",
      "Edge feature dimension: 6\n",
      "Output dimension: 12\n",
      "\n",
      "--- Training GCN Model ---\n",
      "Epoch 1/30, Train Loss: 0.2598, Val Loss: 0.2420, Mean ROC-AUC: 0.6595\n",
      "Epoch 2/30, Train Loss: 0.2393, Val Loss: 0.2364, Mean ROC-AUC: 0.6794\n",
      "Epoch 3/30, Train Loss: 0.2332, Val Loss: 0.2324, Mean ROC-AUC: 0.6958\n",
      "Epoch 4/30, Train Loss: 0.2273, Val Loss: 0.2311, Mean ROC-AUC: 0.7048\n",
      "Epoch 5/30, Train Loss: 0.2216, Val Loss: 0.2262, Mean ROC-AUC: 0.7188\n",
      "Epoch 6/30, Train Loss: 0.2181, Val Loss: 0.2237, Mean ROC-AUC: 0.7313\n",
      "Epoch 7/30, Train Loss: 0.2151, Val Loss: 0.2227, Mean ROC-AUC: 0.7395\n",
      "Epoch 8/30, Train Loss: 0.2121, Val Loss: 0.2197, Mean ROC-AUC: 0.7448\n",
      "Epoch 9/30, Train Loss: 0.2105, Val Loss: 0.2175, Mean ROC-AUC: 0.7527\n",
      "Epoch 10/30, Train Loss: 0.2076, Val Loss: 0.2177, Mean ROC-AUC: 0.7581\n",
      "Epoch 11/30, Train Loss: 0.2053, Val Loss: 0.2226, Mean ROC-AUC: 0.7600\n",
      "Epoch 12/30, Train Loss: 0.2035, Val Loss: 0.2190, Mean ROC-AUC: 0.7638\n",
      "Epoch 13/30, Train Loss: 0.2022, Val Loss: 0.2120, Mean ROC-AUC: 0.7746\n",
      "Epoch 14/30, Train Loss: 0.2001, Val Loss: 0.2130, Mean ROC-AUC: 0.7747\n",
      "Epoch 15/30, Train Loss: 0.1991, Val Loss: 0.2147, Mean ROC-AUC: 0.7782\n",
      "Epoch 16/30, Train Loss: 0.1981, Val Loss: 0.2081, Mean ROC-AUC: 0.7810\n",
      "Epoch 17/30, Train Loss: 0.1958, Val Loss: 0.2131, Mean ROC-AUC: 0.7826\n",
      "Epoch 18/30, Train Loss: 0.1953, Val Loss: 0.2070, Mean ROC-AUC: 0.7883\n",
      "Epoch 19/30, Train Loss: 0.1942, Val Loss: 0.2107, Mean ROC-AUC: 0.7843\n",
      "Epoch 20/30, Train Loss: 0.1924, Val Loss: 0.2066, Mean ROC-AUC: 0.7925\n",
      "Epoch 21/30, Train Loss: 0.1927, Val Loss: 0.2089, Mean ROC-AUC: 0.7905\n",
      "Epoch 22/30, Train Loss: 0.1909, Val Loss: 0.2183, Mean ROC-AUC: 0.7879\n",
      "Epoch 23/30, Train Loss: 0.1903, Val Loss: 0.2065, Mean ROC-AUC: 0.7936\n",
      "Epoch 24/30, Train Loss: 0.1892, Val Loss: 0.2078, Mean ROC-AUC: 0.7977\n",
      "Epoch 25/30, Train Loss: 0.1876, Val Loss: 0.2102, Mean ROC-AUC: 0.7975\n",
      "Epoch 26/30, Train Loss: 0.1868, Val Loss: 0.2053, Mean ROC-AUC: 0.7984\n",
      "Epoch 27/30, Train Loss: 0.1866, Val Loss: 0.2042, Mean ROC-AUC: 0.7984\n",
      "Epoch 28/30, Train Loss: 0.1857, Val Loss: 0.2073, Mean ROC-AUC: 0.7960\n",
      "Epoch 29/30, Train Loss: 0.1850, Val Loss: 0.2054, Mean ROC-AUC: 0.7997\n",
      "Epoch 30/30, Train Loss: 0.1845, Val Loss: 0.2052, Mean ROC-AUC: 0.7994\n",
      "\n",
      "--- Evaluating GCN Model ---\n",
      "\n",
      "GCN Test Metrics:\n",
      "NR-AR: ROC-AUC=0.7480, Accuracy=0.9676\n",
      "NR-AR-LBD: ROC-AUC=0.8668, Accuracy=0.9682\n",
      "NR-AhR: ROC-AUC=0.8745, Accuracy=0.9037\n",
      "NR-Aromatase: ROC-AUC=0.8316, Accuracy=0.9454\n",
      "NR-ER: ROC-AUC=0.7366, Accuracy=0.8733\n",
      "NR-ER-LBD: ROC-AUC=0.8297, Accuracy=0.9489\n",
      "NR-PPAR-gamma: ROC-AUC=0.8262, Accuracy=0.9717\n",
      "SR-ARE: ROC-AUC=0.7841, Accuracy=0.8619\n",
      "SR-ATAD5: ROC-AUC=0.8284, Accuracy=0.9624\n",
      "SR-HSE: ROC-AUC=0.7903, Accuracy=0.9368\n",
      "SR-MMP: ROC-AUC=0.8809, Accuracy=0.8797\n",
      "SR-p53: ROC-AUC=0.8277, Accuracy=0.9298\n",
      "Mean GCN ROC-AUC: 0.8188\n",
      "\n",
      "--- Training MPNN Model ---\n",
      "Epoch 1/30, Train Loss: 0.2601, Val Loss: 0.2434, Mean ROC-AUC: 0.6669\n",
      "Epoch 2/30, Train Loss: 0.2304, Val Loss: 0.2348, Mean ROC-AUC: 0.7047\n",
      "Epoch 3/30, Train Loss: 0.2180, Val Loss: 0.2185, Mean ROC-AUC: 0.7424\n",
      "Epoch 4/30, Train Loss: 0.2094, Val Loss: 0.2211, Mean ROC-AUC: 0.7467\n",
      "Epoch 5/30, Train Loss: 0.2029, Val Loss: 0.2092, Mean ROC-AUC: 0.7663\n",
      "Epoch 6/30, Train Loss: 0.1967, Val Loss: 0.2188, Mean ROC-AUC: 0.7694\n",
      "Epoch 7/30, Train Loss: 0.1927, Val Loss: 0.2083, Mean ROC-AUC: 0.7805\n",
      "Epoch 8/30, Train Loss: 0.1884, Val Loss: 0.2132, Mean ROC-AUC: 0.7840\n",
      "Epoch 9/30, Train Loss: 0.1861, Val Loss: 0.2159, Mean ROC-AUC: 0.7923\n",
      "Epoch 10/30, Train Loss: 0.1823, Val Loss: 0.2018, Mean ROC-AUC: 0.8002\n",
      "Epoch 11/30, Train Loss: 0.1778, Val Loss: 0.2045, Mean ROC-AUC: 0.7940\n",
      "Epoch 12/30, Train Loss: 0.1760, Val Loss: 0.2023, Mean ROC-AUC: 0.8034\n",
      "Epoch 13/30, Train Loss: 0.1745, Val Loss: 0.1993, Mean ROC-AUC: 0.8046\n",
      "Epoch 14/30, Train Loss: 0.1704, Val Loss: 0.2066, Mean ROC-AUC: 0.7950\n",
      "Epoch 15/30, Train Loss: 0.1700, Val Loss: 0.2048, Mean ROC-AUC: 0.8047\n",
      "Epoch 16/30, Train Loss: 0.1653, Val Loss: 0.2046, Mean ROC-AUC: 0.8046\n",
      "Epoch 17/30, Train Loss: 0.1632, Val Loss: 0.2025, Mean ROC-AUC: 0.8147\n",
      "Epoch 18/30, Train Loss: 0.1606, Val Loss: 0.2050, Mean ROC-AUC: 0.8116\n",
      "Epoch 19/30, Train Loss: 0.1599, Val Loss: 0.2032, Mean ROC-AUC: 0.8115\n",
      "Epoch 20/30, Train Loss: 0.1557, Val Loss: 0.2065, Mean ROC-AUC: 0.8053\n",
      "Epoch 21/30, Train Loss: 0.1525, Val Loss: 0.2082, Mean ROC-AUC: 0.8160\n",
      "Epoch 22/30, Train Loss: 0.1506, Val Loss: 0.2086, Mean ROC-AUC: 0.8157\n",
      "Epoch 23/30, Train Loss: 0.1485, Val Loss: 0.2181, Mean ROC-AUC: 0.8049\n",
      "Epoch 24/30, Train Loss: 0.1459, Val Loss: 0.2178, Mean ROC-AUC: 0.8070\n",
      "Epoch 25/30, Train Loss: 0.1444, Val Loss: 0.2141, Mean ROC-AUC: 0.8142\n",
      "Epoch 26/30, Train Loss: 0.1419, Val Loss: 0.2176, Mean ROC-AUC: 0.8133\n",
      "Epoch 27/30, Train Loss: 0.1391, Val Loss: 0.2158, Mean ROC-AUC: 0.8149\n",
      "Epoch 28/30, Train Loss: 0.1368, Val Loss: 0.2188, Mean ROC-AUC: 0.8233\n",
      "Epoch 29/30, Train Loss: 0.1355, Val Loss: 0.2112, Mean ROC-AUC: 0.8233\n",
      "Epoch 30/30, Train Loss: 0.1336, Val Loss: 0.2223, Mean ROC-AUC: 0.8137\n",
      "\n",
      "--- Evaluating MPNN Model ---\n",
      "\n",
      "MPNN Test Metrics:\n",
      "NR-AR: ROC-AUC=0.7680, Accuracy=0.9662\n",
      "NR-AR-LBD: ROC-AUC=0.8290, Accuracy=0.9668\n",
      "NR-AhR: ROC-AUC=0.8739, Accuracy=0.9199\n",
      "NR-Aromatase: ROC-AUC=0.8635, Accuracy=0.9446\n",
      "NR-ER: ROC-AUC=0.7218, Accuracy=0.8765\n",
      "NR-ER-LBD: ROC-AUC=0.8078, Accuracy=0.9468\n",
      "NR-PPAR-gamma: ROC-AUC=0.8477, Accuracy=0.9710\n",
      "SR-ARE: ROC-AUC=0.8217, Accuracy=0.8394\n",
      "SR-ATAD5: ROC-AUC=0.8112, Accuracy=0.9576\n",
      "SR-HSE: ROC-AUC=0.7961, Accuracy=0.9234\n",
      "SR-MMP: ROC-AUC=0.8933, Accuracy=0.8671\n",
      "SR-p53: ROC-AUC=0.8690, Accuracy=0.9193\n",
      "Mean MPNN ROC-AUC: 0.8252\n",
      "\n",
      "--- Model Comparison ---\n",
      "GCN Mean ROC-AUC: 0.8188\n",
      "MPNN Mean ROC-AUC: 0.8252\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, MessagePassing\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load the Tox21 dataset\n",
    "df = pd.read_csv('tox21.csv')\n",
    "\n",
    "# Check for missing values in SMILES\n",
    "print(f\"Number of molecules with missing SMILES: {df['smiles'].isna().sum()}\")\n",
    "\n",
    "# Define the target columns\n",
    "target_columns = [\n",
    "    \"NR-AR\", \"NR-AR-LBD\", \"NR-AhR\", \"NR-Aromatase\", \"NR-ER\", \n",
    "    \"NR-ER-LBD\", \"NR-PPAR-gamma\", \"SR-ARE\", \"SR-ATAD5\", \n",
    "    \"SR-HSE\", \"SR-MMP\", \"SR-p53\"\n",
    "]\n",
    "\n",
    "# Define atom feature extraction function\n",
    "def get_atom_features(atom):\n",
    "    \"\"\"\n",
    "    Returns an array of atom features.\n",
    "    \"\"\"\n",
    "    # Atom type (one-hot encoded)\n",
    "    atom_type_one_hot = np.zeros(100)\n",
    "    atom_num = atom.GetAtomicNum()\n",
    "    if atom_num < 100:\n",
    "        atom_type_one_hot[atom_num] = 1\n",
    "    \n",
    "    # Other atom features\n",
    "    formal_charge = atom.GetFormalCharge()\n",
    "    hybridization = atom.GetHybridization()\n",
    "    is_aromatic = int(atom.GetIsAromatic())\n",
    "    num_h = atom.GetTotalNumHs()\n",
    "    \n",
    "    # Hybridization (one-hot encoded)\n",
    "    hybridization_one_hot = np.zeros(6)\n",
    "    if hybridization.name in ['S', 'SP', 'SP2', 'SP3', 'SP3D', 'SP3D2']:\n",
    "        hyb_idx = ['S', 'SP', 'SP2', 'SP3', 'SP3D', 'SP3D2'].index(hybridization.name)\n",
    "        hybridization_one_hot[hyb_idx] = 1\n",
    "    \n",
    "    # Combine all features\n",
    "    atom_features = np.concatenate([\n",
    "        atom_type_one_hot,\n",
    "        np.array([formal_charge + 4]),  # Shift +4 to ensure positive values\n",
    "        hybridization_one_hot,\n",
    "        np.array([is_aromatic]),\n",
    "        np.array([num_h])\n",
    "    ])\n",
    "    \n",
    "    return atom_features\n",
    "\n",
    "# Define bond feature extraction function\n",
    "def get_bond_features(bond):\n",
    "    \"\"\"\n",
    "    Returns an array of bond features.\n",
    "    \"\"\"\n",
    "    # Bond type (one-hot encoded)\n",
    "    bond_type_one_hot = np.zeros(4)\n",
    "    bond_type = bond.GetBondType()\n",
    "    if bond_type == Chem.rdchem.BondType.SINGLE:\n",
    "        bond_type_one_hot[0] = 1\n",
    "    elif bond_type == Chem.rdchem.BondType.DOUBLE:\n",
    "        bond_type_one_hot[1] = 1\n",
    "    elif bond_type == Chem.rdchem.BondType.TRIPLE:\n",
    "        bond_type_one_hot[2] = 1\n",
    "    elif bond_type == Chem.rdchem.BondType.AROMATIC:\n",
    "        bond_type_one_hot[3] = 1\n",
    "    \n",
    "    # Other bond features\n",
    "    is_conjugated = int(bond.GetIsConjugated())\n",
    "    is_in_ring = int(bond.IsInRing())\n",
    "    \n",
    "    # Combine all features\n",
    "    bond_features = np.concatenate([\n",
    "        bond_type_one_hot,\n",
    "        np.array([is_conjugated, is_in_ring])\n",
    "    ])\n",
    "    \n",
    "    return bond_features\n",
    "\n",
    "# Convert SMILES to molecular graphs\n",
    "def smiles_to_graph(smiles):\n",
    "    \"\"\"\n",
    "    Converts a SMILES string to a PyTorch Geometric Data object containing the molecular graph.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert SMILES to RDKit molecule\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        \n",
    "        if mol is None:\n",
    "            return None\n",
    "            \n",
    "        # Get atom features\n",
    "        atom_features_list = []\n",
    "        for atom in mol.GetAtoms():\n",
    "            atom_features_list.append(get_atom_features(atom))\n",
    "        x = torch.tensor(np.array(atom_features_list), dtype=torch.float)\n",
    "        \n",
    "        # Get edge indices and edge features\n",
    "        edge_indices = []\n",
    "        edge_features_list = []\n",
    "        \n",
    "        for bond in mol.GetBonds():\n",
    "            i = bond.GetBeginAtomIdx()\n",
    "            j = bond.GetEndAtomIdx()\n",
    "            \n",
    "            edge_indices.append([i, j])\n",
    "            edge_indices.append([j, i])  # Add reverse edge for undirected graph\n",
    "            \n",
    "            edge_features = get_bond_features(bond)\n",
    "            edge_features_list.append(edge_features)\n",
    "            edge_features_list.append(edge_features)  # Duplicate for reverse edge\n",
    "            \n",
    "        edge_index = torch.tensor(np.array(edge_indices).T, dtype=torch.long)\n",
    "        edge_attr = torch.tensor(np.array(edge_features_list), dtype=torch.float)\n",
    "        \n",
    "        # Create PyTorch Geometric Data object\n",
    "        data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error converting SMILES to graph: {e}\")\n",
    "        return None\n",
    "\n",
    "# Create a PyTorch Dataset\n",
    "class Tox21Dataset(Dataset):\n",
    "    def __init__(self, dataframe, target_columns, smiles_column='smiles'):\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.target_columns = target_columns\n",
    "        self.smiles_column = smiles_column\n",
    "        \n",
    "        # Convert SMILES to molecular graphs\n",
    "        self.graphs = []\n",
    "        self.valid_indices = []\n",
    "        \n",
    "        for idx, row in tqdm(self.dataframe.iterrows(), total=len(self.dataframe), desc=\"Converting SMILES to graphs\"):\n",
    "            graph = smiles_to_graph(row[self.smiles_column])\n",
    "            if graph is not None:\n",
    "                self.graphs.append(graph)\n",
    "                self.valid_indices.append(idx)\n",
    "        \n",
    "        # Only keep rows with valid graphs\n",
    "        self.dataframe = self.dataframe.iloc[self.valid_indices].reset_index(drop=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        graph = self.graphs[idx]\n",
    "        \n",
    "        # Get targets (handling NaN values)\n",
    "        targets = []\n",
    "        for col in self.target_columns:\n",
    "            value = self.dataframe.loc[idx, col]\n",
    "            # Convert NaN to -1 (will be masked during loss calculation)\n",
    "            targets.append(-1 if pd.isna(value) else value)\n",
    "            \n",
    "        return graph, torch.tensor(targets, dtype=torch.float)\n",
    "\n",
    "# Define Graph Convolutional Network (GCN) model\n",
    "class GCNModel(nn.Module):\n",
    "    def __init__(self, node_features, edge_features, hidden_dim, output_dim):\n",
    "        super(GCNModel, self).__init__()\n",
    "        \n",
    "        # GCN layers\n",
    "        self.conv1 = GCNConv(node_features, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = GCNConv(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # MLP for final prediction\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        # Apply GCN layers with residual connections\n",
    "        x1 = F.relu(self.conv1(x, edge_index))\n",
    "        x2 = F.relu(self.conv2(x1, edge_index)) + x1\n",
    "        x3 = F.relu(self.conv3(x2, edge_index)) + x2\n",
    "        \n",
    "        # Global pooling to get graph-level representation\n",
    "        x = global_mean_pool(x3, batch)\n",
    "        \n",
    "        # Apply MLP for final prediction\n",
    "        out = self.mlp(x)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Define Message Passing Neural Network (MPNN) model\n",
    "class MPNNLayer(MessagePassing):\n",
    "    def __init__(self, node_dim, edge_dim, hidden_dim):\n",
    "        super(MPNNLayer, self).__init__(aggr='add')\n",
    "        \n",
    "        # MLPs for message passing\n",
    "        self.message_mlp = nn.Sequential(\n",
    "            nn.Linear(node_dim + edge_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Update function\n",
    "        self.update_mlp = nn.Sequential(\n",
    "            nn.Linear(node_dim + hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # Start propagating messages\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "    \n",
    "    def message(self, x_i, x_j, edge_attr):\n",
    "        # Create messages based on source nodes and edge features\n",
    "        message_input = torch.cat([x_j, edge_attr], dim=1)\n",
    "        return self.message_mlp(message_input)\n",
    "    \n",
    "    def update(self, aggr_out, x):\n",
    "        # Update node embeddings\n",
    "        update_input = torch.cat([x, aggr_out], dim=1)\n",
    "        return self.update_mlp(update_input)\n",
    "\n",
    "class MPNNModel(nn.Module):\n",
    "    def __init__(self, node_features, edge_features, hidden_dim, output_dim):\n",
    "        super(MPNNModel, self).__init__()\n",
    "        \n",
    "        # MPNN layers\n",
    "        self.mpnn1 = MPNNLayer(node_features, edge_features, hidden_dim)\n",
    "        self.mpnn2 = MPNNLayer(hidden_dim, edge_features, hidden_dim)\n",
    "        self.mpnn3 = MPNNLayer(hidden_dim, edge_features, hidden_dim)\n",
    "        \n",
    "        # MLP for final prediction\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        \n",
    "        # Apply MPNN layers with residual connections\n",
    "        x1 = F.relu(self.mpnn1(x, edge_index, edge_attr))\n",
    "        x2 = F.relu(self.mpnn2(x1, edge_index, edge_attr)) + x1\n",
    "        x3 = F.relu(self.mpnn3(x2, edge_index, edge_attr)) + x2\n",
    "        \n",
    "        # Global pooling to get graph-level representation\n",
    "        x = global_mean_pool(x3, batch)\n",
    "        \n",
    "        # Apply MLP for final prediction\n",
    "        out = self.mlp(x)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Define a masked loss function to handle missing values\n",
    "def masked_bce_loss(pred, target):\n",
    "    # Create a mask for non-missing values (where target != -1)\n",
    "    mask = (target != -1).float()\n",
    "    \n",
    "    # Apply sigmoid to get probabilities\n",
    "    pred_probs = torch.sigmoid(pred)\n",
    "    \n",
    "    # Compute BCE loss only for non-missing values\n",
    "    loss = F.binary_cross_entropy_with_logits(pred, target * mask, reduction='none')\n",
    "    loss = loss * mask  # Zero out loss for missing values\n",
    "    \n",
    "    # Compute mean loss over non-missing values\n",
    "    non_missing = mask.sum()\n",
    "    if non_missing > 0:\n",
    "        return loss.sum() / non_missing\n",
    "    else:\n",
    "        return torch.tensor(0.0, device=pred.device)\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, optimizer, num_epochs=50, device='cuda'):\n",
    "    model.to(device)\n",
    "    best_val_roc_auc = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_roc_aucs = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for data, targets in train_loader:\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(data)\n",
    "            loss = masked_bce_loss(outputs, targets)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item() * len(targets)\n",
    "        \n",
    "        avg_train_loss = epoch_loss / len(train_loader.dataset)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        all_targets = []\n",
    "        all_outputs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, targets in val_loader:\n",
    "                data = data.to(device)\n",
    "                targets = targets.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(data)\n",
    "                loss = masked_bce_loss(outputs, targets)\n",
    "                \n",
    "                val_loss += loss.item() * len(targets)\n",
    "                \n",
    "                # Store predictions and targets for ROC-AUC calculation\n",
    "                # Only store non-missing values\n",
    "                mask = (targets != -1).cpu().numpy()\n",
    "                all_targets.append(targets.cpu().numpy())\n",
    "                all_outputs.append(outputs.cpu().numpy())\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        # Compute ROC-AUC for each task\n",
    "        all_targets = np.vstack(all_targets)\n",
    "        all_outputs = np.vstack(all_outputs)\n",
    "        \n",
    "        task_roc_aucs = []\n",
    "        for task_idx in range(len(target_columns)):\n",
    "            # Get mask for non-missing values\n",
    "            mask = (all_targets[:, task_idx] != -1)\n",
    "            if mask.sum() > 0 and len(np.unique(all_targets[mask, task_idx])) > 1:\n",
    "                y_true = all_targets[mask, task_idx]\n",
    "                y_score = all_outputs[mask, task_idx]\n",
    "                try:\n",
    "                    roc_auc = roc_auc_score(y_true, y_score)\n",
    "                    task_roc_aucs.append(roc_auc)\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        if task_roc_aucs:\n",
    "            mean_roc_auc = np.mean(task_roc_aucs)\n",
    "            val_roc_aucs.append(mean_roc_auc)\n",
    "            \n",
    "            # Save best model\n",
    "            if mean_roc_auc > best_val_roc_auc:\n",
    "                best_val_roc_auc = mean_roc_auc\n",
    "                best_model_state = model.state_dict().copy()\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Mean ROC-AUC: {mean_roc_auc:.4f}\")\n",
    "        else:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Mean ROC-AUC: N/A\")\n",
    "    \n",
    "    # Load best model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    return model, train_losses, val_losses, val_roc_aucs\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, test_loader, device='cuda'):\n",
    "    model.eval()\n",
    "    all_targets = []\n",
    "    all_outputs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            data = data.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(data)\n",
    "            \n",
    "            # Store predictions and targets\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "            all_outputs.append(outputs.cpu().numpy())\n",
    "    \n",
    "    all_targets = np.vstack(all_targets)\n",
    "    all_outputs = np.vstack(all_outputs)\n",
    "    \n",
    "    # Compute metrics for each task\n",
    "    task_metrics = {}\n",
    "    for task_idx, task_name in enumerate(target_columns):\n",
    "        # Get mask for non-missing values\n",
    "        mask = (all_targets[:, task_idx] != -1)\n",
    "        if mask.sum() > 0 and len(np.unique(all_targets[mask, task_idx])) > 1:\n",
    "            y_true = all_targets[mask, task_idx]\n",
    "            y_score = all_outputs[mask, task_idx]\n",
    "            y_pred = (y_score > 0).astype(int)  # Threshold at 0 (sigmoid=0.5)\n",
    "            \n",
    "            try:\n",
    "                task_roc_auc = roc_auc_score(y_true, y_score)\n",
    "                task_accuracy = accuracy_score(y_true, y_pred)\n",
    "                \n",
    "                task_metrics[task_name] = {\n",
    "                    'roc_auc': task_roc_auc,\n",
    "                    'accuracy': task_accuracy\n",
    "                }\n",
    "            except:\n",
    "                task_metrics[task_name] = {\n",
    "                    'roc_auc': np.nan,\n",
    "                    'accuracy': np.nan\n",
    "                }\n",
    "    \n",
    "    return task_metrics\n",
    "\n",
    "# Main function to run the full pipeline\n",
    "def main():\n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    df = pd.read_csv('tox21.csv')\n",
    "    \n",
    "    # Split data into train, validation, and test sets (64%, 16%, 20%)\n",
    "    # train_df, temp_df = train_test_split(df, test_size=0.36, random_state=42)  # 64% for training\n",
    "    # val_df, test_df = train_test_split(temp_df, test_size=0.5556, random_state=42)  # 16% for validation, 20% for testing\n",
    "\n",
    "    train_df = pd.read_csv('tox21_train.csv')\n",
    "    val_df = pd.read_csv('tox21_val.csv')  \n",
    "    test_df = pd.read_csv('tox21_test.csv')\n",
    "    \n",
    "    print(f\"Train set size: {len(train_df)}\")\n",
    "    print(f\"Validation set size: {len(val_df)}\")\n",
    "    print(f\"Test set size: {len(test_df)}\")\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = Tox21Dataset(train_df, target_columns)\n",
    "    val_dataset = Tox21Dataset(val_df, target_columns)\n",
    "    test_dataset = Tox21Dataset(test_df, target_columns)\n",
    "    \n",
    "    print(f\"Train dataset size after processing: {len(train_dataset)}\")\n",
    "    print(f\"Validation dataset size after processing: {len(val_dataset)}\")\n",
    "    print(f\"Test dataset size after processing: {len(test_dataset)}\")\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=Batch.from_data_list)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=Batch.from_data_list)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=Batch.from_data_list)\n",
    "    \n",
    "    # Get dimensions for model initialization\n",
    "    sample_graph = train_dataset[0][0]\n",
    "    node_features = sample_graph.x.size(1)\n",
    "    edge_features = sample_graph.edge_attr.size(1)\n",
    "    output_dim = len(target_columns)\n",
    "    \n",
    "    print(f\"Node feature dimension: {node_features}\")\n",
    "    print(f\"Edge feature dimension: {edge_features}\")\n",
    "    print(f\"Output dimension: {output_dim}\")\n",
    "    \n",
    "    # Initialize models\n",
    "    gcn_model = GCNModel(node_features, edge_features, hidden_dim=64, output_dim=output_dim)\n",
    "    mpnn_model = MPNNModel(node_features, edge_features, hidden_dim=64, output_dim=output_dim)\n",
    "    \n",
    "    # Train and evaluate GCN model\n",
    "    print(\"\\n--- Training GCN Model ---\")\n",
    "    gcn_optimizer = torch.optim.Adam(gcn_model.parameters(), lr=0.001)\n",
    "    gcn_model, gcn_train_losses, gcn_val_losses, gcn_val_roc_aucs = train_model(\n",
    "        gcn_model, train_loader, val_loader, gcn_optimizer, num_epochs=30, device=device\n",
    "    )\n",
    "    \n",
    "    # Evaluate GCN model on test set\n",
    "    print(\"\\n--- Evaluating GCN Model ---\")\n",
    "    gcn_metrics = evaluate_model(gcn_model, test_loader, device=device)\n",
    "    \n",
    "    # Print GCN metrics\n",
    "    print(\"\\nGCN Test Metrics:\")\n",
    "    gcn_roc_aucs = []\n",
    "    for task, metrics in gcn_metrics.items():\n",
    "        print(f\"{task}: ROC-AUC={metrics['roc_auc']:.4f}, Accuracy={metrics['accuracy']:.4f}\")\n",
    "        gcn_roc_aucs.append(metrics['roc_auc'])\n",
    "    \n",
    "    print(f\"Mean GCN ROC-AUC: {np.nanmean(gcn_roc_aucs):.4f}\")\n",
    "    \n",
    "    # Train and evaluate MPNN model\n",
    "    print(\"\\n--- Training MPNN Model ---\")\n",
    "    mpnn_optimizer = torch.optim.Adam(mpnn_model.parameters(), lr=0.001)\n",
    "    mpnn_model, mpnn_train_losses, mpnn_val_losses, mpnn_val_roc_aucs = train_model(\n",
    "        mpnn_model, train_loader, val_loader, mpnn_optimizer, num_epochs=30, device=device\n",
    "    )\n",
    "    \n",
    "    # Evaluate MPNN model on test set\n",
    "    print(\"\\n--- Evaluating MPNN Model ---\")\n",
    "    mpnn_metrics = evaluate_model(mpnn_model, test_loader, device=device)\n",
    "    \n",
    "    # Print MPNN metrics\n",
    "    print(\"\\nMPNN Test Metrics:\")\n",
    "    mpnn_roc_aucs = []\n",
    "    for task, metrics in mpnn_metrics.items():\n",
    "        print(f\"{task}: ROC-AUC={metrics['roc_auc']:.4f}, Accuracy={metrics['accuracy']:.4f}\")\n",
    "        mpnn_roc_aucs.append(metrics['roc_auc'])\n",
    "    \n",
    "    print(f\"Mean MPNN ROC-AUC: {np.nanmean(mpnn_roc_aucs):.4f}\")\n",
    "    \n",
    "    # Compare GCN and MPNN results\n",
    "    print(\"\\n--- Model Comparison ---\")\n",
    "    print(f\"GCN Mean ROC-AUC: {np.nanmean(gcn_roc_aucs):.4f}\")\n",
    "    print(f\"MPNN Mean ROC-AUC: {np.nanmean(mpnn_roc_aucs):.4f}\")\n",
    "    \n",
    "    # Plot training curves\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(gcn_train_losses, label='GCN Train Loss')\n",
    "    plt.plot(gcn_val_losses, label='GCN Val Loss')\n",
    "    plt.plot(mpnn_train_losses, label='MPNN Train Loss')\n",
    "    plt.plot(mpnn_val_losses, label='MPNN Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Loss')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(gcn_val_roc_aucs, label='GCN ROC-AUC')\n",
    "    plt.plot(mpnn_val_roc_aucs, label='MPNN ROC-AUC')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('ROC-AUC')\n",
    "    plt.legend()\n",
    "    plt.title('Validation ROC-AUC')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('gnn_training_curves.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Create performance comparison bar chart\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Get data for plotting\n",
    "    tasks = list(gcn_metrics.keys())\n",
    "    gcn_scores = [metrics['roc_auc'] for metrics in gcn_metrics.values()]\n",
    "    mpnn_scores = [metrics['roc_auc'] for metrics in mpnn_metrics.values()]\n",
    "    \n",
    "    x = np.arange(len(tasks))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.bar(x - width/2, gcn_scores, width, label='GCN')\n",
    "    plt.bar(x + width/2, mpnn_scores, width, label='MPNN')\n",
    "    \n",
    "    plt.xlabel('Target')\n",
    "    plt.ylabel('ROC-AUC')\n",
    "    plt.title('Model Performance Comparison')\n",
    "    plt.xticks(x, tasks, rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('gnn_performance_comparison.png')\n",
    "    plt.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f35e3c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSS5104",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
