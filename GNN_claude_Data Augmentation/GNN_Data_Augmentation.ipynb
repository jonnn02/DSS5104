{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eccece40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of molecules with missing SMILES: 0\n",
      "Using device: cuda\n",
      "Train set size: 20492\n",
      "Validation set size: 5072\n",
      "Test set size: 6460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting SMILES to graphs: 100%|██████████| 20492/20492 [00:08<00:00, 2340.85it/s]\n",
      "Converting SMILES to graphs: 100%|██████████| 5072/5072 [00:02<00:00, 2468.11it/s]\n",
      "Converting SMILES to graphs:   0%|          | 0/6460 [00:00<?, ?it/s][19:16:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[19:16:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[19:16:30] WARNING: not removing hydrogen atom without neighbors\n",
      "[19:16:30] WARNING: not removing hydrogen atom without neighbors\n",
      "Converting SMILES to graphs: 100%|██████████| 6460/6460 [00:02<00:00, 2456.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size after processing: 20492\n",
      "Validation dataset size after processing: 5072\n",
      "Test dataset size after processing: 6460\n",
      "Node feature dimension: 109\n",
      "Edge feature dimension: 6\n",
      "Output dimension: 12\n",
      "\n",
      "--- Training GCN Model ---\n",
      "Epoch 1/30, Train Loss: 0.2604, Val Loss: 0.2421, Mean ROC-AUC: 0.6435\n",
      "Epoch 2/30, Train Loss: 0.2390, Val Loss: 0.2361, Mean ROC-AUC: 0.6816\n",
      "Epoch 3/30, Train Loss: 0.2325, Val Loss: 0.2332, Mean ROC-AUC: 0.6986\n",
      "Epoch 4/30, Train Loss: 0.2274, Val Loss: 0.2294, Mean ROC-AUC: 0.7068\n",
      "Epoch 5/30, Train Loss: 0.2227, Val Loss: 0.2269, Mean ROC-AUC: 0.7180\n",
      "Epoch 6/30, Train Loss: 0.2194, Val Loss: 0.2253, Mean ROC-AUC: 0.7253\n",
      "Epoch 7/30, Train Loss: 0.2176, Val Loss: 0.2267, Mean ROC-AUC: 0.7383\n",
      "Epoch 8/30, Train Loss: 0.2149, Val Loss: 0.2235, Mean ROC-AUC: 0.7433\n",
      "Epoch 9/30, Train Loss: 0.2127, Val Loss: 0.2211, Mean ROC-AUC: 0.7495\n",
      "Epoch 10/30, Train Loss: 0.2098, Val Loss: 0.2189, Mean ROC-AUC: 0.7565\n",
      "Epoch 11/30, Train Loss: 0.2084, Val Loss: 0.2169, Mean ROC-AUC: 0.7579\n",
      "Epoch 12/30, Train Loss: 0.2060, Val Loss: 0.2156, Mean ROC-AUC: 0.7664\n",
      "Epoch 13/30, Train Loss: 0.2048, Val Loss: 0.2154, Mean ROC-AUC: 0.7689\n",
      "Epoch 14/30, Train Loss: 0.2030, Val Loss: 0.2158, Mean ROC-AUC: 0.7705\n",
      "Epoch 15/30, Train Loss: 0.2016, Val Loss: 0.2131, Mean ROC-AUC: 0.7728\n",
      "Epoch 16/30, Train Loss: 0.2002, Val Loss: 0.2122, Mean ROC-AUC: 0.7739\n",
      "Epoch 17/30, Train Loss: 0.1990, Val Loss: 0.2111, Mean ROC-AUC: 0.7801\n",
      "Epoch 18/30, Train Loss: 0.1976, Val Loss: 0.2114, Mean ROC-AUC: 0.7781\n",
      "Epoch 19/30, Train Loss: 0.1971, Val Loss: 0.2088, Mean ROC-AUC: 0.7820\n",
      "Epoch 20/30, Train Loss: 0.1960, Val Loss: 0.2080, Mean ROC-AUC: 0.7832\n",
      "Epoch 21/30, Train Loss: 0.1955, Val Loss: 0.2083, Mean ROC-AUC: 0.7862\n",
      "Epoch 22/30, Train Loss: 0.1953, Val Loss: 0.2100, Mean ROC-AUC: 0.7846\n",
      "Epoch 23/30, Train Loss: 0.1933, Val Loss: 0.2081, Mean ROC-AUC: 0.7889\n",
      "Epoch 24/30, Train Loss: 0.1924, Val Loss: 0.2072, Mean ROC-AUC: 0.7895\n",
      "Epoch 25/30, Train Loss: 0.1915, Val Loss: 0.2055, Mean ROC-AUC: 0.7891\n",
      "Epoch 26/30, Train Loss: 0.1909, Val Loss: 0.2079, Mean ROC-AUC: 0.7839\n",
      "Epoch 27/30, Train Loss: 0.1897, Val Loss: 0.2170, Mean ROC-AUC: 0.7875\n",
      "Epoch 28/30, Train Loss: 0.1891, Val Loss: 0.2098, Mean ROC-AUC: 0.7931\n",
      "Epoch 29/30, Train Loss: 0.1882, Val Loss: 0.2094, Mean ROC-AUC: 0.7894\n",
      "Epoch 30/30, Train Loss: 0.1869, Val Loss: 0.2061, Mean ROC-AUC: 0.7907\n",
      "\n",
      "--- Evaluating GCN Model ---\n",
      "Saved GCN detailed predictions to gcn_prediction_details.csv\n",
      "\n",
      "GCN Test Metrics:\n",
      "NR-AR: ROC-AUC=0.7587, Accuracy=0.9662\n",
      "NR-AR-LBD: ROC-AUC=0.8389, Accuracy=0.9653\n",
      "NR-AhR: ROC-AUC=0.8708, Accuracy=0.9103\n",
      "NR-Aromatase: ROC-AUC=0.8088, Accuracy=0.9454\n",
      "NR-ER: ROC-AUC=0.7282, Accuracy=0.8765\n",
      "NR-ER-LBD: ROC-AUC=0.8361, Accuracy=0.9482\n",
      "NR-PPAR-gamma: ROC-AUC=0.8456, Accuracy=0.9725\n",
      "SR-ARE: ROC-AUC=0.7731, Accuracy=0.8586\n",
      "SR-ATAD5: ROC-AUC=0.7831, Accuracy=0.9583\n",
      "SR-HSE: ROC-AUC=0.7795, Accuracy=0.9338\n",
      "SR-MMP: ROC-AUC=0.8749, Accuracy=0.8789\n",
      "SR-p53: ROC-AUC=0.8154, Accuracy=0.9333\n",
      "Mean GCN ROC-AUC: 0.8094\n",
      "\n",
      "--- Training MPNN Model ---\n",
      "Epoch 1/30, Train Loss: 0.2593, Val Loss: 0.2438, Mean ROC-AUC: 0.6523\n",
      "Epoch 2/30, Train Loss: 0.2316, Val Loss: 0.2279, Mean ROC-AUC: 0.7088\n",
      "Epoch 3/30, Train Loss: 0.2210, Val Loss: 0.2223, Mean ROC-AUC: 0.7262\n",
      "Epoch 4/30, Train Loss: 0.2101, Val Loss: 0.2196, Mean ROC-AUC: 0.7415\n",
      "Epoch 5/30, Train Loss: 0.2052, Val Loss: 0.2190, Mean ROC-AUC: 0.7469\n",
      "Epoch 6/30, Train Loss: 0.2010, Val Loss: 0.2098, Mean ROC-AUC: 0.7676\n",
      "Epoch 7/30, Train Loss: 0.1954, Val Loss: 0.2120, Mean ROC-AUC: 0.7770\n",
      "Epoch 8/30, Train Loss: 0.1916, Val Loss: 0.2131, Mean ROC-AUC: 0.7778\n",
      "Epoch 9/30, Train Loss: 0.1871, Val Loss: 0.2045, Mean ROC-AUC: 0.7953\n",
      "Epoch 10/30, Train Loss: 0.1848, Val Loss: 0.2090, Mean ROC-AUC: 0.7949\n",
      "Epoch 11/30, Train Loss: 0.1815, Val Loss: 0.2019, Mean ROC-AUC: 0.8011\n",
      "Epoch 12/30, Train Loss: 0.1792, Val Loss: 0.2052, Mean ROC-AUC: 0.7988\n",
      "Epoch 13/30, Train Loss: 0.1768, Val Loss: 0.2033, Mean ROC-AUC: 0.8060\n",
      "Epoch 14/30, Train Loss: 0.1742, Val Loss: 0.2098, Mean ROC-AUC: 0.7938\n",
      "Epoch 15/30, Train Loss: 0.1701, Val Loss: 0.2048, Mean ROC-AUC: 0.8018\n",
      "Epoch 16/30, Train Loss: 0.1672, Val Loss: 0.2111, Mean ROC-AUC: 0.8002\n",
      "Epoch 17/30, Train Loss: 0.1669, Val Loss: 0.2051, Mean ROC-AUC: 0.8070\n",
      "Epoch 18/30, Train Loss: 0.1628, Val Loss: 0.2058, Mean ROC-AUC: 0.8063\n",
      "Epoch 19/30, Train Loss: 0.1608, Val Loss: 0.2046, Mean ROC-AUC: 0.8054\n",
      "Epoch 20/30, Train Loss: 0.1588, Val Loss: 0.2086, Mean ROC-AUC: 0.8037\n",
      "Epoch 21/30, Train Loss: 0.1568, Val Loss: 0.2055, Mean ROC-AUC: 0.8101\n",
      "Epoch 22/30, Train Loss: 0.1533, Val Loss: 0.2161, Mean ROC-AUC: 0.7937\n",
      "Epoch 23/30, Train Loss: 0.1520, Val Loss: 0.2093, Mean ROC-AUC: 0.8070\n",
      "Epoch 24/30, Train Loss: 0.1490, Val Loss: 0.2070, Mean ROC-AUC: 0.8150\n",
      "Epoch 25/30, Train Loss: 0.1455, Val Loss: 0.2160, Mean ROC-AUC: 0.8058\n",
      "Epoch 26/30, Train Loss: 0.1424, Val Loss: 0.2082, Mean ROC-AUC: 0.8175\n",
      "Epoch 27/30, Train Loss: 0.1408, Val Loss: 0.2183, Mean ROC-AUC: 0.8150\n",
      "Epoch 28/30, Train Loss: 0.1378, Val Loss: 0.2189, Mean ROC-AUC: 0.8179\n",
      "Epoch 29/30, Train Loss: 0.1373, Val Loss: 0.2100, Mean ROC-AUC: 0.8139\n",
      "Epoch 30/30, Train Loss: 0.1343, Val Loss: 0.2258, Mean ROC-AUC: 0.8090\n",
      "\n",
      "--- Evaluating MPNN Model ---\n",
      "Saved MPNN detailed predictions to mpnn_prediction_details.csv\n",
      "\n",
      "MPNN Test Metrics:\n",
      "NR-AR: ROC-AUC=0.7567, Accuracy=0.9715\n",
      "NR-AR-LBD: ROC-AUC=0.8629, Accuracy=0.9745\n",
      "NR-AhR: ROC-AUC=0.8825, Accuracy=0.9066\n",
      "NR-Aromatase: ROC-AUC=0.8663, Accuracy=0.9488\n",
      "NR-ER: ROC-AUC=0.7278, Accuracy=0.8733\n",
      "NR-ER-LBD: ROC-AUC=0.8116, Accuracy=0.9544\n",
      "NR-PPAR-gamma: ROC-AUC=0.8657, Accuracy=0.9740\n",
      "SR-ARE: ROC-AUC=0.8166, Accuracy=0.8502\n",
      "SR-ATAD5: ROC-AUC=0.8122, Accuracy=0.9597\n",
      "SR-HSE: ROC-AUC=0.7772, Accuracy=0.9330\n",
      "SR-MMP: ROC-AUC=0.8849, Accuracy=0.8730\n",
      "SR-p53: ROC-AUC=0.8614, Accuracy=0.9291\n",
      "Mean MPNN ROC-AUC: 0.8272\n",
      "\n",
      "--- Model Comparison ---\n",
      "GCN Mean ROC-AUC: 0.8094\n",
      "MPNN Mean ROC-AUC: 0.8272\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, MessagePassing\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load the Tox21 dataset\n",
    "df = pd.read_csv('tox21.csv')\n",
    "\n",
    "# Check for missing values in SMILES\n",
    "print(f\"Number of molecules with missing SMILES: {df['smiles'].isna().sum()}\")\n",
    "\n",
    "# Define the target columns\n",
    "target_columns = [\n",
    "    \"NR-AR\", \"NR-AR-LBD\", \"NR-AhR\", \"NR-Aromatase\", \"NR-ER\", \n",
    "    \"NR-ER-LBD\", \"NR-PPAR-gamma\", \"SR-ARE\", \"SR-ATAD5\", \n",
    "    \"SR-HSE\", \"SR-MMP\", \"SR-p53\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Define atom feature extraction function\n",
    "def get_atom_features(atom):\n",
    "    \"\"\"\n",
    "    Returns an array of atom features.\n",
    "    \"\"\"\n",
    "    # Atom type (one-hot encoded)\n",
    "    atom_type_one_hot = np.zeros(100)\n",
    "    atom_num = atom.GetAtomicNum()\n",
    "    if atom_num < 100:\n",
    "        atom_type_one_hot[atom_num] = 1\n",
    "    \n",
    "    # Other atom features\n",
    "    formal_charge = atom.GetFormalCharge()\n",
    "    hybridization = atom.GetHybridization()\n",
    "    is_aromatic = int(atom.GetIsAromatic())\n",
    "    num_h = atom.GetTotalNumHs()\n",
    "    \n",
    "    # Hybridization (one-hot encoded)\n",
    "    hybridization_one_hot = np.zeros(6)\n",
    "    if hybridization.name in ['S', 'SP', 'SP2', 'SP3', 'SP3D', 'SP3D2']:\n",
    "        hyb_idx = ['S', 'SP', 'SP2', 'SP3', 'SP3D', 'SP3D2'].index(hybridization.name)\n",
    "        hybridization_one_hot[hyb_idx] = 1\n",
    "    \n",
    "    # Combine all features\n",
    "    atom_features = np.concatenate([\n",
    "        atom_type_one_hot,\n",
    "        np.array([formal_charge + 4]),  # Shift +4 to ensure positive values\n",
    "        hybridization_one_hot,\n",
    "        np.array([is_aromatic]),\n",
    "        np.array([num_h])\n",
    "    ])\n",
    "    \n",
    "    return atom_features\n",
    "\n",
    "# Define bond feature extraction function\n",
    "def get_bond_features(bond):\n",
    "    \"\"\"\n",
    "    Returns an array of bond features.\n",
    "    \"\"\"\n",
    "    # Bond type (one-hot encoded)\n",
    "    bond_type_one_hot = np.zeros(4)\n",
    "    bond_type = bond.GetBondType()\n",
    "    if bond_type == Chem.rdchem.BondType.SINGLE:\n",
    "        bond_type_one_hot[0] = 1\n",
    "    elif bond_type == Chem.rdchem.BondType.DOUBLE:\n",
    "        bond_type_one_hot[1] = 1\n",
    "    elif bond_type == Chem.rdchem.BondType.TRIPLE:\n",
    "        bond_type_one_hot[2] = 1\n",
    "    elif bond_type == Chem.rdchem.BondType.AROMATIC:\n",
    "        bond_type_one_hot[3] = 1\n",
    "    \n",
    "    # Other bond features\n",
    "    is_conjugated = int(bond.GetIsConjugated())\n",
    "    is_in_ring = int(bond.IsInRing())\n",
    "    \n",
    "    # Combine all features\n",
    "    bond_features = np.concatenate([\n",
    "        bond_type_one_hot,\n",
    "        np.array([is_conjugated, is_in_ring])\n",
    "    ])\n",
    "    \n",
    "    return bond_features\n",
    "\n",
    "# Convert SMILES to molecular graphs\n",
    "def smiles_to_graph(smiles):\n",
    "    \"\"\"\n",
    "    Converts a SMILES string to a PyTorch Geometric Data object containing the molecular graph.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert SMILES to RDKit molecule\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        \n",
    "        if mol is None:\n",
    "            return None\n",
    "            \n",
    "        # Get atom features\n",
    "        atom_features_list = []\n",
    "        for atom in mol.GetAtoms():\n",
    "            atom_features_list.append(get_atom_features(atom))\n",
    "        x = torch.tensor(np.array(atom_features_list), dtype=torch.float)\n",
    "        \n",
    "        # Get edge indices and edge features\n",
    "        edge_indices = []\n",
    "        edge_features_list = []\n",
    "        \n",
    "        for bond in mol.GetBonds():\n",
    "            i = bond.GetBeginAtomIdx()\n",
    "            j = bond.GetEndAtomIdx()\n",
    "            \n",
    "            edge_indices.append([i, j])\n",
    "            edge_indices.append([j, i])  # Add reverse edge for undirected graph\n",
    "            \n",
    "            edge_features = get_bond_features(bond)\n",
    "            edge_features_list.append(edge_features)\n",
    "            edge_features_list.append(edge_features)  # Duplicate for reverse edge\n",
    "            \n",
    "        edge_index = torch.tensor(np.array(edge_indices).T, dtype=torch.long)\n",
    "        edge_attr = torch.tensor(np.array(edge_features_list), dtype=torch.float)\n",
    "        \n",
    "        # Create PyTorch Geometric Data object\n",
    "        data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error converting SMILES to graph: {e}\")\n",
    "        return None\n",
    "\n",
    "# Create a PyTorch Dataset\n",
    "class Tox21Dataset(Dataset):\n",
    "    def __init__(self, dataframe, target_columns, smiles_column='smiles'):\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.target_columns = target_columns\n",
    "        self.smiles_column = smiles_column\n",
    "        \n",
    "        # Convert SMILES to molecular graphs\n",
    "        self.graphs = []\n",
    "        self.valid_indices = []\n",
    "        \n",
    "        for idx, row in tqdm(self.dataframe.iterrows(), total=len(self.dataframe), desc=\"Converting SMILES to graphs\"):\n",
    "            graph = smiles_to_graph(row[self.smiles_column])\n",
    "            if graph is not None:\n",
    "                self.graphs.append(graph)\n",
    "                self.valid_indices.append(idx)\n",
    "        \n",
    "        # Only keep rows with valid graphs\n",
    "        self.dataframe = self.dataframe.iloc[self.valid_indices].reset_index(drop=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        graph = self.graphs[idx]\n",
    "        \n",
    "        # Get targets (handling NaN values)\n",
    "        targets = []\n",
    "        for col in self.target_columns:\n",
    "            value = self.dataframe.loc[idx, col]\n",
    "            # Convert NaN to -1 (will be masked during loss calculation)\n",
    "            targets.append(-1 if pd.isna(value) else value)\n",
    "            \n",
    "        return graph, torch.tensor(targets, dtype=torch.float)\n",
    "\n",
    "# Define Graph Convolutional Network (GCN) model\n",
    "class GCNModel(nn.Module):\n",
    "    def __init__(self, node_features, edge_features, hidden_dim, output_dim):\n",
    "        super(GCNModel, self).__init__()\n",
    "        \n",
    "        # GCN layers\n",
    "        self.conv1 = GCNConv(node_features, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = GCNConv(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # MLP for final prediction\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        # Apply GCN layers with residual connections\n",
    "        x1 = F.relu(self.conv1(x, edge_index))\n",
    "        x2 = F.relu(self.conv2(x1, edge_index)) + x1\n",
    "        x3 = F.relu(self.conv3(x2, edge_index)) + x2\n",
    "        \n",
    "        # Global pooling to get graph-level representation\n",
    "        x = global_mean_pool(x3, batch)\n",
    "        \n",
    "        # Apply MLP for final prediction\n",
    "        out = self.mlp(x)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Define Message Passing Neural Network (MPNN) model\n",
    "class MPNNLayer(MessagePassing):\n",
    "    def __init__(self, node_dim, edge_dim, hidden_dim):\n",
    "        super(MPNNLayer, self).__init__(aggr='add')\n",
    "        \n",
    "        # MLPs for message passing\n",
    "        self.message_mlp = nn.Sequential(\n",
    "            nn.Linear(node_dim + edge_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Update function\n",
    "        self.update_mlp = nn.Sequential(\n",
    "            nn.Linear(node_dim + hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # Start propagating messages\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "    \n",
    "    def message(self, x_i, x_j, edge_attr):\n",
    "        # Create messages based on source nodes and edge features\n",
    "        message_input = torch.cat([x_j, edge_attr], dim=1)\n",
    "        return self.message_mlp(message_input)\n",
    "    \n",
    "    def update(self, aggr_out, x):\n",
    "        # Update node embeddings\n",
    "        update_input = torch.cat([x, aggr_out], dim=1)\n",
    "        return self.update_mlp(update_input)\n",
    "\n",
    "class MPNNModel(nn.Module):\n",
    "    def __init__(self, node_features, edge_features, hidden_dim, output_dim):\n",
    "        super(MPNNModel, self).__init__()\n",
    "        \n",
    "        # MPNN layers\n",
    "        self.mpnn1 = MPNNLayer(node_features, edge_features, hidden_dim)\n",
    "        self.mpnn2 = MPNNLayer(hidden_dim, edge_features, hidden_dim)\n",
    "        self.mpnn3 = MPNNLayer(hidden_dim, edge_features, hidden_dim)\n",
    "        \n",
    "        # MLP for final prediction\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        \n",
    "        # Apply MPNN layers with residual connections\n",
    "        x1 = F.relu(self.mpnn1(x, edge_index, edge_attr))\n",
    "        x2 = F.relu(self.mpnn2(x1, edge_index, edge_attr)) + x1\n",
    "        x3 = F.relu(self.mpnn3(x2, edge_index, edge_attr)) + x2\n",
    "        \n",
    "        # Global pooling to get graph-level representation\n",
    "        x = global_mean_pool(x3, batch)\n",
    "        \n",
    "        # Apply MLP for final prediction\n",
    "        out = self.mlp(x)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Define a masked loss function to handle missing values\n",
    "def masked_bce_loss(pred, target):\n",
    "    # Create a mask for non-missing values (where target != -1)\n",
    "    mask = (target != -1).float()\n",
    "    \n",
    "    # Apply sigmoid to get probabilities\n",
    "    pred_probs = torch.sigmoid(pred)\n",
    "    \n",
    "    # Compute BCE loss only for non-missing values\n",
    "    loss = F.binary_cross_entropy_with_logits(pred, target * mask, reduction='none')\n",
    "    loss = loss * mask  # Zero out loss for missing values\n",
    "    \n",
    "    # Compute mean loss over non-missing values\n",
    "    non_missing = mask.sum()\n",
    "    if non_missing > 0:\n",
    "        return loss.sum() / non_missing\n",
    "    else:\n",
    "        return torch.tensor(0.0, device=pred.device)\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, optimizer, num_epochs=50, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    best_val_roc_auc = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_roc_aucs = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for data, targets in train_loader:\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(data)\n",
    "            loss = masked_bce_loss(outputs, targets)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item() * len(targets)\n",
    "        \n",
    "        avg_train_loss = epoch_loss / len(train_loader.dataset)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        all_targets = []\n",
    "        all_outputs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, targets in val_loader:\n",
    "                data = data.to(device)\n",
    "                targets = targets.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(data)\n",
    "                loss = masked_bce_loss(outputs, targets)\n",
    "                \n",
    "                val_loss += loss.item() * len(targets)\n",
    "                \n",
    "                # Store predictions and targets for ROC-AUC calculation\n",
    "                # Only store non-missing values\n",
    "                mask = (targets != -1).cpu().numpy()\n",
    "                all_targets.append(targets.cpu().numpy())\n",
    "                all_outputs.append(outputs.cpu().numpy())\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        # Compute ROC-AUC for each task\n",
    "        all_targets = np.vstack(all_targets)\n",
    "        all_outputs = np.vstack(all_outputs)\n",
    "        \n",
    "        task_roc_aucs = []\n",
    "        for task_idx in range(len(target_columns)):\n",
    "            # Get mask for non-missing values\n",
    "            mask = (all_targets[:, task_idx] != -1)\n",
    "            if mask.sum() > 0 and len(np.unique(all_targets[mask, task_idx])) > 1:\n",
    "                y_true = all_targets[mask, task_idx]\n",
    "                y_score = all_outputs[mask, task_idx]\n",
    "                try:\n",
    "                    roc_auc = roc_auc_score(y_true, y_score)\n",
    "                    task_roc_aucs.append(roc_auc)\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        if task_roc_aucs:\n",
    "            mean_roc_auc = np.mean(task_roc_aucs)\n",
    "            val_roc_aucs.append(mean_roc_auc)\n",
    "            \n",
    "            # Save best model\n",
    "            if mean_roc_auc > best_val_roc_auc:\n",
    "                best_val_roc_auc = mean_roc_auc\n",
    "                best_model_state = model.state_dict().copy()\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Mean ROC-AUC: {mean_roc_auc:.4f}\")\n",
    "        else:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Mean ROC-AUC: N/A\")\n",
    "    \n",
    "    # Load best model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    return model, train_losses, val_losses, val_roc_aucs\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, test_loader, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    all_targets = []\n",
    "    all_outputs = []\n",
    "    all_scores  = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(data)\n",
    "            \n",
    "            # Store predictions and targets\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "            all_outputs.append(outputs.cpu().numpy())\n",
    "\n",
    "\n",
    "    all_targets = np.vstack(all_targets)\n",
    "    all_outputs = np.vstack(all_outputs)\n",
    "    \n",
    "    # Compute metrics for each task\n",
    "    task_metrics = {}\n",
    "    for task_idx, task_name in enumerate(target_columns):\n",
    "        # Get mask for non-missing values\n",
    "        mask = (all_targets[:, task_idx] != -1)\n",
    "        if mask.sum() > 0 and len(np.unique(all_targets[mask, task_idx])) > 1:\n",
    "            y_true = all_targets[mask, task_idx]\n",
    "            y_score = all_outputs[mask, task_idx]\n",
    "            y_pred = (y_score > 0).astype(int)  # Threshold at 0 (sigmoid=0.5)\n",
    "            \n",
    "            try:\n",
    "                task_roc_auc = roc_auc_score(y_true, y_score)\n",
    "                task_accuracy = accuracy_score(y_true, y_pred)\n",
    "                \n",
    "                task_metrics[task_name] = {\n",
    "                    'roc_auc': task_roc_auc,\n",
    "                    'accuracy': task_accuracy\n",
    "                }\n",
    "            except:\n",
    "                task_metrics[task_name] = {\n",
    "                    'roc_auc': np.nan,\n",
    "                    'accuracy': np.nan\n",
    "                }\n",
    "    \n",
    "    return task_metrics, all_targets, all_outputs \n",
    "\n",
    "# Main function to run the full pipeline\n",
    "def main():\n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    df = pd.read_csv('tox21.csv')\n",
    "    \n",
    "    # Split data into train, validation, and test sets (64%, 16%, 20%)\n",
    "    # train_df, temp_df = train_test_split(df, test_size=0.36, random_state=42)  # 64% for training\n",
    "    # val_df, test_df = train_test_split(temp_df, test_size=0.5556, random_state=42)  # 16% for validation, 20% for testing\n",
    "\n",
    "    train_df = pd.read_csv('tox21_train.csv')\n",
    "    val_df = pd.read_csv('tox21_val.csv')  \n",
    "    test_df = pd.read_csv('tox21_test.csv')\n",
    "    \n",
    "    print(f\"Train set size: {len(train_df)}\")\n",
    "    print(f\"Validation set size: {len(val_df)}\")\n",
    "    print(f\"Test set size: {len(test_df)}\")\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = Tox21Dataset(train_df, target_columns)\n",
    "    val_dataset = Tox21Dataset(val_df, target_columns)\n",
    "    test_dataset = Tox21Dataset(test_df, target_columns)\n",
    "    \n",
    "    print(f\"Train dataset size after processing: {len(train_dataset)}\")\n",
    "    print(f\"Validation dataset size after processing: {len(val_dataset)}\")\n",
    "    print(f\"Test dataset size after processing: {len(test_dataset)}\")\n",
    "    \n",
    "    # Create data loaders\n",
    "    # train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=Batch.from_data_list)\n",
    "    # val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=Batch.from_data_list)\n",
    "    # test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=Batch.from_data_list)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Get dimensions for model initialization\n",
    "    sample_graph = train_dataset[0][0]\n",
    "    node_features = sample_graph.x.size(1)\n",
    "    edge_features = sample_graph.edge_attr.size(1)\n",
    "    output_dim = len(target_columns)\n",
    "    \n",
    "    print(f\"Node feature dimension: {node_features}\")\n",
    "    print(f\"Edge feature dimension: {edge_features}\")\n",
    "    print(f\"Output dimension: {output_dim}\")\n",
    "    \n",
    "    # Initialize models\n",
    "    gcn_model = GCNModel(node_features, edge_features, hidden_dim=64, output_dim=output_dim).to(device)\n",
    "    mpnn_model = MPNNModel(node_features, edge_features, hidden_dim=64, output_dim=output_dim).to(device)\n",
    "    \n",
    "    # Train and evaluate GCN model\n",
    "    print(\"\\n--- Training GCN Model ---\")\n",
    "    gcn_optimizer = torch.optim.Adam(gcn_model.parameters(), lr=0.001)\n",
    "    gcn_model, gcn_train_losses, gcn_val_losses, gcn_val_roc_aucs = train_model(\n",
    "        gcn_model, train_loader, val_loader, gcn_optimizer, num_epochs=30, device=device\n",
    "    )\n",
    "    \n",
    "    # Evaluate GCN model on test set\n",
    "    print(\"\\n--- Evaluating GCN Model ---\")\n",
    "    gcn_metrics, gcn_y_true, gcn_y_score = evaluate_model(gcn_model, test_loader, device=device)\n",
    "    \n",
    "    gcn_rows = []\n",
    "    N, T = gcn_y_true.shape\n",
    "    for i in range(N):\n",
    "        for j, task in enumerate(target_columns):\n",
    "            true = int(gcn_y_true[i, j])\n",
    "            if true == -1:\n",
    "                continue\n",
    "            prob = float(torch.sigmoid(torch.tensor(gcn_y_score[i, j])).item())\n",
    "            pred = 1 if prob > 0.5 else 0\n",
    "            gcn_rows.append({\n",
    "                'sample_id':       i,\n",
    "                'task':            task,\n",
    "                'predicted_prob':  prob,\n",
    "                'predicted_label': pred,\n",
    "                'true_label':      true\n",
    "            })\n",
    "    gcn_df = pd.DataFrame(gcn_rows)\n",
    "    gcn_df.to_csv('gcn_prediction_details.csv', index=False)\n",
    "    print(\"Saved GCN detailed predictions to gcn_prediction_details.csv\")\n",
    "\n",
    "    # Print GCN metrics\n",
    "    print(\"\\nGCN Test Metrics:\")\n",
    "    gcn_roc_aucs = []\n",
    "    for task, metrics in gcn_metrics.items():\n",
    "        print(f\"{task}: ROC-AUC={metrics['roc_auc']:.4f}, Accuracy={metrics['accuracy']:.4f}\")\n",
    "        gcn_roc_aucs.append(metrics['roc_auc'])\n",
    "    \n",
    "    print(f\"Mean GCN ROC-AUC: {np.nanmean(gcn_roc_aucs):.4f}\")\n",
    "    \n",
    "    # Train and evaluate MPNN model\n",
    "    print(\"\\n--- Training MPNN Model ---\")\n",
    "    mpnn_optimizer = torch.optim.Adam(mpnn_model.parameters(), lr=0.001)\n",
    "    mpnn_model, mpnn_train_losses, mpnn_val_losses, mpnn_val_roc_aucs = train_model(\n",
    "        mpnn_model, train_loader, val_loader, mpnn_optimizer, num_epochs=30, device=device\n",
    "    )\n",
    "    \n",
    "    # Evaluate MPNN model on test set\n",
    "    print(\"\\n--- Evaluating MPNN Model ---\")\n",
    "    mpnn_metrics, mpnn_y_true, mpnn_y_score = evaluate_model(mpnn_model, test_loader, device=device)\n",
    "\n",
    "    mpnn_rows = []\n",
    "    N, T = mpnn_y_true.shape\n",
    "    for i in range(N):\n",
    "        for j, task in enumerate(target_columns):\n",
    "            true = int(mpnn_y_true[i, j])\n",
    "            if true == -1:\n",
    "                continue\n",
    "            prob = float(torch.sigmoid(torch.tensor(mpnn_y_score[i, j])).item())\n",
    "            pred = 1 if prob > 0.5 else 0\n",
    "            mpnn_rows.append({\n",
    "                'sample_id':       i,\n",
    "                'task':            task,\n",
    "                'predicted_prob':  prob,\n",
    "                'predicted_label': pred,\n",
    "                'true_label':      true\n",
    "            })\n",
    "    mpnn_df = pd.DataFrame(mpnn_rows)\n",
    "    mpnn_df.to_csv('mpnn_prediction_details.csv', index=False)\n",
    "    print(\"Saved MPNN detailed predictions to mpnn_prediction_details.csv\")\n",
    "    \n",
    "    # Print MPNN metrics\n",
    "    print(\"\\nMPNN Test Metrics:\")\n",
    "    mpnn_roc_aucs = []\n",
    "    for task, metrics in mpnn_metrics.items():\n",
    "        print(f\"{task}: ROC-AUC={metrics['roc_auc']:.4f}, Accuracy={metrics['accuracy']:.4f}\")\n",
    "        mpnn_roc_aucs.append(metrics['roc_auc'])\n",
    "    \n",
    "    print(f\"Mean MPNN ROC-AUC: {np.nanmean(mpnn_roc_aucs):.4f}\")\n",
    "    \n",
    "    # Compare GCN and MPNN results\n",
    "    print(\"\\n--- Model Comparison ---\")\n",
    "    print(f\"GCN Mean ROC-AUC: {np.nanmean(gcn_roc_aucs):.4f}\")\n",
    "    print(f\"MPNN Mean ROC-AUC: {np.nanmean(mpnn_roc_aucs):.4f}\")\n",
    "\n",
    "    gcn_metrics, gcn_y_true, gcn_y_score = evaluate_model(gcn_model, test_loader, device=device)\n",
    "    \n",
    "    # Plot training curves\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(gcn_train_losses, label='GCN Train Loss')\n",
    "    plt.plot(gcn_val_losses, label='GCN Val Loss')\n",
    "    plt.plot(mpnn_train_losses, label='MPNN Train Loss')\n",
    "    plt.plot(mpnn_val_losses, label='MPNN Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Loss')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(gcn_val_roc_aucs, label='GCN ROC-AUC')\n",
    "    plt.plot(mpnn_val_roc_aucs, label='MPNN ROC-AUC')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('ROC-AUC')\n",
    "    plt.legend()\n",
    "    plt.title('Validation ROC-AUC')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('gnn_training_curves.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Create performance comparison bar chart\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Get data for plotting\n",
    "    tasks = list(gcn_metrics.keys())\n",
    "    gcn_scores = [metrics['roc_auc'] for metrics in gcn_metrics.values()]\n",
    "    mpnn_scores = [metrics['roc_auc'] for metrics in mpnn_metrics.values()]\n",
    "    \n",
    "    x = np.arange(len(tasks))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.bar(x - width/2, gcn_scores, width, label='GCN')\n",
    "    plt.bar(x + width/2, mpnn_scores, width, label='MPNN')\n",
    "    \n",
    "    plt.xlabel('Target')\n",
    "    plt.ylabel('ROC-AUC')\n",
    "    plt.title('Model Performance Comparison')\n",
    "    plt.xticks(x, tasks, rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('gnn_performance_comparison.png')\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for idx, task_name in enumerate(target_columns):\n",
    "        # 挑出非缺失项\n",
    "        mask = gcn_y_true[:, idx] != -1\n",
    "        if mask.sum() > 1 and len(np.unique(gcn_y_true[mask, idx])) > 1:\n",
    "            fpr, tpr, _ = roc_curve(\n",
    "                gcn_y_true[mask, idx],\n",
    "                gcn_y_score[mask, idx]\n",
    "            )\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, lw=2,\n",
    "                     label=f\"{task_name} (AUC = {roc_auc:.2f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"GCN Model ROC Curves\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"gcn_roc_curves.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # … 然后同理画 MPNN …\n",
    "    mpnn_metrics, mpnn_y_true, mpnn_y_score = evaluate_model(\n",
    "        mpnn_model, test_loader, device=device\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for idx, task_name in enumerate(target_columns):\n",
    "        mask = mpnn_y_true[:, idx] != -1\n",
    "        if mask.sum() > 1 and len(np.unique(mpnn_y_true[mask, idx])) > 1:\n",
    "            fpr, tpr, _ = roc_curve(\n",
    "                mpnn_y_true[mask, idx],\n",
    "                mpnn_y_score[mask, idx]\n",
    "            )\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, lw=2,\n",
    "                     label=f\"{task_name} (AUC = {roc_auc:.2f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"MPNN Model ROC Curves\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"mpnn_roc_curves.png\")\n",
    "    plt.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97639b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSS5104",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
