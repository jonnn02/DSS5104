{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhqxAQuefeCP",
        "outputId": "88bcfce9-bb0f-4cbf-d6cd-8361575b67c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training LSTM...\n",
            "Epoch 1/90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 114ms/step - AUC: 0.6376 - loss: 0.1635 - val_AUC: 0.7606 - val_loss: 0.1240\n",
            "Epoch 2/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 116ms/step - AUC: 0.7644 - loss: 0.1120 - val_AUC: 0.7829 - val_loss: 0.1209\n",
            "Epoch 3/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 111ms/step - AUC: 0.8012 - loss: 0.1049 - val_AUC: 0.8002 - val_loss: 0.1195\n",
            "Epoch 4/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 115ms/step - AUC: 0.8210 - loss: 0.0999 - val_AUC: 0.8113 - val_loss: 0.1176\n",
            "Epoch 5/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 115ms/step - AUC: 0.8349 - loss: 0.0968 - val_AUC: 0.8093 - val_loss: 0.1185\n",
            "Epoch 6/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 112ms/step - AUC: 0.8458 - loss: 0.0956 - val_AUC: 0.8006 - val_loss: 0.1212\n",
            "Epoch 7/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 112ms/step - AUC: 0.8502 - loss: 0.0931 - val_AUC: 0.8050 - val_loss: 0.1193\n",
            "Epoch 8/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 113ms/step - AUC: 0.8605 - loss: 0.0900 - val_AUC: 0.8027 - val_loss: 0.1199\n",
            "Epoch 9/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 115ms/step - AUC: 0.8679 - loss: 0.0912 - val_AUC: 0.8027 - val_loss: 0.1206\n",
            "Epoch 10/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 114ms/step - AUC: 0.8759 - loss: 0.0886 - val_AUC: 0.7848 - val_loss: 0.1234\n",
            "Epoch 11/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 114ms/step - AUC: 0.8767 - loss: 0.0897 - val_AUC: 0.7897 - val_loss: 0.1239\n",
            "Epoch 12/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 115ms/step - AUC: 0.8833 - loss: 0.0856 - val_AUC: 0.7874 - val_loss: 0.1229\n",
            "Epoch 13/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 114ms/step - AUC: 0.8933 - loss: 0.0857 - val_AUC: 0.7843 - val_loss: 0.1242\n",
            "Epoch 14/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 113ms/step - AUC: 0.8980 - loss: 0.0814 - val_AUC: 0.7822 - val_loss: 0.1258\n",
            "Epoch 15/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 115ms/step - AUC: 0.9006 - loss: 0.0812 - val_AUC: 0.7859 - val_loss: 0.1248\n",
            "Epoch 16/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 114ms/step - AUC: 0.9105 - loss: 0.0786 - val_AUC: 0.7748 - val_loss: 0.1305\n",
            "Epoch 17/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 115ms/step - AUC: 0.9148 - loss: 0.0765 - val_AUC: 0.7768 - val_loss: 0.1295\n",
            "Epoch 18/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 116ms/step - AUC: 0.9132 - loss: 0.0778 - val_AUC: 0.7817 - val_loss: 0.1311\n",
            "Epoch 19/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 114ms/step - AUC: 0.9161 - loss: 0.0741 - val_AUC: 0.7683 - val_loss: 0.1338\n",
            "Epoch 20/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 116ms/step - AUC: 0.9261 - loss: 0.0711 - val_AUC: 0.7664 - val_loss: 0.1345\n",
            "Epoch 21/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 115ms/step - AUC: 0.9310 - loss: 0.0702 - val_AUC: 0.7639 - val_loss: 0.1363\n",
            "Epoch 22/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 114ms/step - AUC: 0.9279 - loss: 0.0714 - val_AUC: 0.7565 - val_loss: 0.1390\n",
            "Epoch 23/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 113ms/step - AUC: 0.9347 - loss: 0.0691 - val_AUC: 0.7592 - val_loss: 0.1416\n",
            "Epoch 24/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 117ms/step - AUC: 0.9378 - loss: 0.0665 - val_AUC: 0.7566 - val_loss: 0.1425\n",
            "Epoch 25/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 115ms/step - AUC: 0.9376 - loss: 0.0666 - val_AUC: 0.7426 - val_loss: 0.1468\n",
            "Epoch 26/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 115ms/step - AUC: 0.9383 - loss: 0.0664 - val_AUC: 0.7352 - val_loss: 0.1485\n",
            "Epoch 27/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 113ms/step - AUC: 0.9434 - loss: 0.0643 - val_AUC: 0.7351 - val_loss: 0.1521\n",
            "Epoch 28/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 115ms/step - AUC: 0.9456 - loss: 0.0632 - val_AUC: 0.7325 - val_loss: 0.1522\n",
            "Epoch 29/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 115ms/step - AUC: 0.9480 - loss: 0.0621 - val_AUC: 0.7347 - val_loss: 0.1515\n",
            "Epoch 30/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 114ms/step - AUC: 0.9422 - loss: 0.0640 - val_AUC: 0.7210 - val_loss: 0.1600\n",
            "Epoch 31/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 116ms/step - AUC: 0.9498 - loss: 0.0606 - val_AUC: 0.7128 - val_loss: 0.1609\n",
            "Epoch 32/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 116ms/step - AUC: 0.9492 - loss: 0.0624 - val_AUC: 0.7338 - val_loss: 0.1578\n",
            "Epoch 33/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 116ms/step - AUC: 0.9506 - loss: 0.0611 - val_AUC: 0.7102 - val_loss: 0.1599\n",
            "Epoch 34/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 115ms/step - AUC: 0.9544 - loss: 0.0586 - val_AUC: 0.7126 - val_loss: 0.1646\n",
            "Epoch 35/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 115ms/step - AUC: 0.9559 - loss: 0.0580 - val_AUC: 0.7088 - val_loss: 0.1680\n",
            "Epoch 36/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 115ms/step - AUC: 0.9558 - loss: 0.0574 - val_AUC: 0.6947 - val_loss: 0.1727\n",
            "Epoch 37/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 116ms/step - AUC: 0.9589 - loss: 0.0573 - val_AUC: 0.6983 - val_loss: 0.1733\n",
            "Epoch 38/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 117ms/step - AUC: 0.9584 - loss: 0.0560 - val_AUC: 0.7140 - val_loss: 0.1678\n",
            "Epoch 39/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 117ms/step - AUC: 0.9609 - loss: 0.0543 - val_AUC: 0.7005 - val_loss: 0.1747\n",
            "Epoch 40/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 117ms/step - AUC: 0.9627 - loss: 0.0536 - val_AUC: 0.6903 - val_loss: 0.1798\n",
            "Epoch 41/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 117ms/step - AUC: 0.9639 - loss: 0.0529 - val_AUC: 0.6892 - val_loss: 0.1784\n",
            "Epoch 42/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 116ms/step - AUC: 0.9640 - loss: 0.0525 - val_AUC: 0.6847 - val_loss: 0.1860\n",
            "Epoch 43/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 117ms/step - AUC: 0.9667 - loss: 0.0528 - val_AUC: 0.6866 - val_loss: 0.1843\n",
            "Epoch 44/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 117ms/step - AUC: 0.9662 - loss: 0.0514 - val_AUC: 0.6893 - val_loss: 0.1811\n",
            "Epoch 45/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 117ms/step - AUC: 0.9667 - loss: 0.0518 - val_AUC: 0.6655 - val_loss: 0.1924\n",
            "Epoch 46/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 117ms/step - AUC: 0.9680 - loss: 0.0523 - val_AUC: 0.6855 - val_loss: 0.1878\n",
            "Epoch 47/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 116ms/step - AUC: 0.9675 - loss: 0.0505 - val_AUC: 0.6867 - val_loss: 0.1933\n",
            "Epoch 48/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 117ms/step - AUC: 0.9689 - loss: 0.0495 - val_AUC: 0.6667 - val_loss: 0.1980\n",
            "Epoch 49/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 117ms/step - AUC: 0.9673 - loss: 0.0502 - val_AUC: 0.6646 - val_loss: 0.1993\n",
            "Epoch 50/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 117ms/step - AUC: 0.9698 - loss: 0.0485 - val_AUC: 0.6552 - val_loss: 0.2057\n",
            "Epoch 51/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 116ms/step - AUC: 0.9688 - loss: 0.0491 - val_AUC: 0.6676 - val_loss: 0.1981\n",
            "Epoch 52/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 116ms/step - AUC: 0.9737 - loss: 0.0468 - val_AUC: 0.6694 - val_loss: 0.2003\n",
            "Epoch 53/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 116ms/step - AUC: 0.9705 - loss: 0.0487 - val_AUC: 0.6649 - val_loss: 0.2012\n",
            "Epoch 54/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 118ms/step - AUC: 0.9743 - loss: 0.0457 - val_AUC: 0.6710 - val_loss: 0.2005\n",
            "Epoch 55/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 116ms/step - AUC: 0.9735 - loss: 0.0457 - val_AUC: 0.6627 - val_loss: 0.2071\n",
            "Epoch 56/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 117ms/step - AUC: 0.9748 - loss: 0.0455 - val_AUC: 0.6682 - val_loss: 0.2086\n",
            "Epoch 57/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 116ms/step - AUC: 0.9660 - loss: 0.0504 - val_AUC: 0.6715 - val_loss: 0.1933\n",
            "Epoch 58/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 116ms/step - AUC: 0.9668 - loss: 0.0511 - val_AUC: 0.6686 - val_loss: 0.1985\n",
            "Epoch 59/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 116ms/step - AUC: 0.9739 - loss: 0.0456 - val_AUC: 0.6604 - val_loss: 0.2093\n",
            "Epoch 60/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 118ms/step - AUC: 0.9764 - loss: 0.0439 - val_AUC: 0.6712 - val_loss: 0.2058\n",
            "Epoch 61/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 118ms/step - AUC: 0.9787 - loss: 0.0435 - val_AUC: 0.6675 - val_loss: 0.2105\n",
            "Epoch 62/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 117ms/step - AUC: 0.9774 - loss: 0.0439 - val_AUC: 0.6669 - val_loss: 0.2101\n",
            "Epoch 63/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 117ms/step - AUC: 0.9764 - loss: 0.0440 - val_AUC: 0.6622 - val_loss: 0.2163\n",
            "Epoch 64/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 118ms/step - AUC: 0.9771 - loss: 0.0431 - val_AUC: 0.6704 - val_loss: 0.2125\n",
            "Epoch 65/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 116ms/step - AUC: 0.9761 - loss: 0.0444 - val_AUC: 0.6540 - val_loss: 0.2218\n",
            "Epoch 66/90\n",
            "\u001b[1m983/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 117ms/step - AUC: 0.9799 - loss: 0.0416 - val_AUC: 0.6588 - val_loss: 0.2238\n",
            "Epoch 67/90\n",
            "\u001b[1m925/983\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m6s\u001b[0m 117ms/step - AUC: 0.9776 - loss: 0.0435"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
        "import matplotlib.pyplot as plt\n",
        "from rdkit import Chem\n",
        "\n",
        "# === Load Datasets ===\n",
        "train_df = pd.read_csv(\"tox21_train.csv\")\n",
        "val_df = pd.read_csv(\"tox21_val.csv\")\n",
        "test_df = pd.read_csv(\"tox21_test.csv\")\n",
        "\n",
        "# === Define Targets ===\n",
        "targets = [\n",
        "    \"NR-AR\", \"NR-AR-LBD\", \"NR-AhR\", \"NR-Aromatase\", \"NR-ER\", \"NR-ER-LBD\",\n",
        "    \"NR-PPAR-gamma\", \"SR-ARE\", \"SR-ATAD5\", \"SR-HSE\", \"SR-MMP\", \"SR-p53\"\n",
        "]\n",
        "\n",
        "# === SMILES Augmentation Functions ===\n",
        "def randomize_smiles(smiles, num_aug=5):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return []\n",
        "    return [Chem.MolToSmiles(mol, doRandom=True) for _ in range(num_aug)]\n",
        "\n",
        "def augment_dataframe(df, label_columns, num_aug=3):\n",
        "    augmented_rows = []\n",
        "    for _, row in df.iterrows():\n",
        "        base_smiles = row['smiles']\n",
        "        labels = row[label_columns]\n",
        "        augmented_rows.append({'smiles': base_smiles, **labels.to_dict()})\n",
        "        for s in randomize_smiles(base_smiles, num_aug=num_aug):\n",
        "            augmented_rows.append({'smiles': s, **labels.to_dict()})\n",
        "    return pd.DataFrame(augmented_rows)\n",
        "\n",
        "# === Preprocess Each Set ===\n",
        "train_df = train_df.dropna(subset=[\"smiles\"] + targets)\n",
        "val_df = val_df.dropna(subset=[\"smiles\"] + targets)\n",
        "test_df = test_df.dropna(subset=[\"smiles\"] + targets)\n",
        "\n",
        "# Apply augmentation to training set\n",
        "train_df = augment_dataframe(train_df, targets, num_aug=3)\n",
        "\n",
        "# Tokenizer (fit only on augmented training set)\n",
        "tokenizer = Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(train_df[\"smiles\"].astype(str))\n",
        "\n",
        "def preprocess(df, tokenizer, maxlen=200):\n",
        "    sequences = tokenizer.texts_to_sequences(df[\"smiles\"].astype(str))\n",
        "    X = pad_sequences(sequences, maxlen=maxlen)\n",
        "    Y = df[targets].astype(int).values\n",
        "    return X, Y\n",
        "\n",
        "X_train, Y_train = preprocess(train_df, tokenizer)\n",
        "X_val, Y_val = preprocess(val_df, tokenizer)\n",
        "X_test, Y_test = preprocess(test_df, tokenizer)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# === ROC Plot ===\n",
        "def plot_roc_curve(y_true, y_pred, name):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    for i in range(y_true.shape[1]):\n",
        "        fpr, tpr, _ = roc_curve(y_true[:, i], y_pred[:, i])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, label=f'{targets[i]} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
        "    plt.title(f'{name} ROC Curve')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "# === Model Evaluation ===\n",
        "def evaluate_model(model, name):\n",
        "    y_pred = model.predict(X_test)\n",
        "    aucs = []\n",
        "    for i in range(Y_test.shape[1]):\n",
        "        try:\n",
        "            auc_score = roc_auc_score(Y_test[:, i], y_pred[:, i])\n",
        "        except ValueError:\n",
        "            auc_score = np.nan\n",
        "        aucs.append(auc_score)\n",
        "    print(f\"\\n{name} ROC-AUCs:\")\n",
        "    for i, target in enumerate(targets):\n",
        "        print(f\"{target:15s}: ROC-AUC = {aucs[i]:.3f}\")\n",
        "    plot_roc_curve(Y_test, y_pred, name)\n",
        "    return aucs\n",
        "\n",
        "# === Model Builders ===\n",
        "def build_lstm():\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=vocab_size, output_dim=64, input_length=200),\n",
        "        LSTM(64),\n",
        "        Dropout(0.3),\n",
        "        Dense(12, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['AUC'])\n",
        "    return model\n",
        "\n",
        "def build_bilstm():\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=vocab_size, output_dim=64, input_length=200),\n",
        "        Bidirectional(LSTM(64)),\n",
        "        Dropout(0.3),\n",
        "        Dense(12, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['AUC'])\n",
        "    return model\n",
        "\n",
        "def build_cnn():\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=vocab_size, output_dim=64, input_length=200),\n",
        "        Conv1D(128, kernel_size=5, activation='relu'),\n",
        "        GlobalMaxPooling1D(),\n",
        "        Dropout(0.3),\n",
        "        Dense(12, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['AUC'])\n",
        "    return model\n",
        "\n",
        "# === Train & Evaluate Each Model ===\n",
        "for name, builder in [(\"LSTM\", build_lstm), (\"BiLSTM\", build_bilstm), (\"1D-CNN\", build_cnn)]:\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    model = builder()\n",
        "    model.fit(X_train, Y_train, epochs=90, batch_size=32, validation_data=(X_val, Y_val), verbose=1)\n",
        "    evaluate_model(model, name)\n"
      ]
    }
  ]
}