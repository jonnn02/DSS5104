{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e7c2e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of molecules with missing SMILES: 0\n",
      "Using device: cpu\n",
      "Train set size: 5123\n",
      "Validation set size: 1281\n",
      "Test set size: 1602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting SMILES to graphs:  45%|████▍     | 2301/5123 [00:01<00:01, 2245.63it/s][23:51:48] WARNING: not removing hydrogen atom without neighbors\n",
      "Converting SMILES to graphs: 100%|██████████| 5123/5123 [00:02<00:00, 2266.43it/s]\n",
      "Converting SMILES to graphs: 100%|██████████| 1281/1281 [00:00<00:00, 2284.05it/s]\n",
      "Converting SMILES to graphs: 100%|██████████| 1602/1602 [00:00<00:00, 2295.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size after processing: 5123\n",
      "Validation dataset size after processing: 1281\n",
      "Test dataset size after processing: 1602\n",
      "Node feature dimension: 109\n",
      "Edge feature dimension: 6\n",
      "Output dimension: 12\n",
      "\n",
      "--- Training GCN Model ---\n",
      "Epoch 1/30, Train Loss: 0.3014, Val Loss: 0.2500, Mean ROC-AUC: 0.6338\n",
      "Epoch 2/30, Train Loss: 0.2527, Val Loss: 0.2495, Mean ROC-AUC: 0.6462\n",
      "Epoch 3/30, Train Loss: 0.2511, Val Loss: 0.2444, Mean ROC-AUC: 0.6563\n",
      "Epoch 4/30, Train Loss: 0.2468, Val Loss: 0.2418, Mean ROC-AUC: 0.7058\n",
      "Epoch 5/30, Train Loss: 0.2450, Val Loss: 0.2397, Mean ROC-AUC: 0.7078\n",
      "Epoch 6/30, Train Loss: 0.2415, Val Loss: 0.2402, Mean ROC-AUC: 0.7159\n",
      "Epoch 7/30, Train Loss: 0.2422, Val Loss: 0.2392, Mean ROC-AUC: 0.7197\n",
      "Epoch 8/30, Train Loss: 0.2393, Val Loss: 0.2363, Mean ROC-AUC: 0.7230\n",
      "Epoch 9/30, Train Loss: 0.2372, Val Loss: 0.2365, Mean ROC-AUC: 0.7249\n",
      "Epoch 10/30, Train Loss: 0.2359, Val Loss: 0.2355, Mean ROC-AUC: 0.7281\n",
      "Epoch 11/30, Train Loss: 0.2350, Val Loss: 0.2368, Mean ROC-AUC: 0.7289\n",
      "Epoch 12/30, Train Loss: 0.2327, Val Loss: 0.2347, Mean ROC-AUC: 0.7340\n",
      "Epoch 13/30, Train Loss: 0.2306, Val Loss: 0.2348, Mean ROC-AUC: 0.7363\n",
      "Epoch 14/30, Train Loss: 0.2327, Val Loss: 0.2346, Mean ROC-AUC: 0.7402\n",
      "Epoch 15/30, Train Loss: 0.2277, Val Loss: 0.2307, Mean ROC-AUC: 0.7431\n",
      "Epoch 16/30, Train Loss: 0.2280, Val Loss: 0.2391, Mean ROC-AUC: 0.7438\n",
      "Epoch 17/30, Train Loss: 0.2274, Val Loss: 0.2317, Mean ROC-AUC: 0.7450\n",
      "Epoch 18/30, Train Loss: 0.2251, Val Loss: 0.2349, Mean ROC-AUC: 0.7457\n",
      "Epoch 19/30, Train Loss: 0.2268, Val Loss: 0.2280, Mean ROC-AUC: 0.7523\n",
      "Epoch 20/30, Train Loss: 0.2238, Val Loss: 0.2293, Mean ROC-AUC: 0.7575\n",
      "Epoch 21/30, Train Loss: 0.2228, Val Loss: 0.2302, Mean ROC-AUC: 0.7593\n",
      "Epoch 22/30, Train Loss: 0.2220, Val Loss: 0.2263, Mean ROC-AUC: 0.7605\n",
      "Epoch 23/30, Train Loss: 0.2202, Val Loss: 0.2552, Mean ROC-AUC: 0.7622\n",
      "Epoch 24/30, Train Loss: 0.2220, Val Loss: 0.2285, Mean ROC-AUC: 0.7666\n",
      "Epoch 25/30, Train Loss: 0.2174, Val Loss: 0.2250, Mean ROC-AUC: 0.7697\n",
      "Epoch 26/30, Train Loss: 0.2179, Val Loss: 0.2241, Mean ROC-AUC: 0.7704\n",
      "Epoch 27/30, Train Loss: 0.2172, Val Loss: 0.2242, Mean ROC-AUC: 0.7717\n",
      "Epoch 28/30, Train Loss: 0.2162, Val Loss: 0.2271, Mean ROC-AUC: 0.7754\n",
      "Epoch 29/30, Train Loss: 0.2180, Val Loss: 0.2252, Mean ROC-AUC: 0.7751\n",
      "Epoch 30/30, Train Loss: 0.2164, Val Loss: 0.2290, Mean ROC-AUC: 0.7787\n",
      "\n",
      "--- Evaluating GCN Model ---\n",
      "\n",
      "GCN Test Metrics:\n",
      "NR-AR: ROC-AUC=0.7192, Accuracy=0.9619\n",
      "NR-AR-LBD: ROC-AUC=0.8017, Accuracy=0.9685\n",
      "NR-AhR: ROC-AUC=0.8682, Accuracy=0.8872\n",
      "NR-Aromatase: ROC-AUC=0.7207, Accuracy=0.9528\n",
      "NR-ER: ROC-AUC=0.6811, Accuracy=0.8711\n",
      "NR-ER-LBD: ROC-AUC=0.7996, Accuracy=0.9503\n",
      "NR-PPAR-gamma: ROC-AUC=0.7867, Accuracy=0.9744\n",
      "SR-ARE: ROC-AUC=0.7147, Accuracy=0.8511\n",
      "SR-ATAD5: ROC-AUC=0.7962, Accuracy=0.9685\n",
      "SR-HSE: ROC-AUC=0.7152, Accuracy=0.9503\n",
      "SR-MMP: ROC-AUC=0.8146, Accuracy=0.8561\n",
      "SR-p53: ROC-AUC=0.7480, Accuracy=0.9410\n",
      "Mean GCN ROC-AUC: 0.7638\n",
      "\n",
      "--- Training MPNN Model ---\n",
      "Epoch 1/30, Train Loss: 0.3083, Val Loss: 0.2516, Mean ROC-AUC: 0.6249\n",
      "Epoch 2/30, Train Loss: 0.2524, Val Loss: 0.2473, Mean ROC-AUC: 0.6701\n",
      "Epoch 3/30, Train Loss: 0.2473, Val Loss: 0.2432, Mean ROC-AUC: 0.6993\n",
      "Epoch 4/30, Train Loss: 0.2411, Val Loss: 0.2374, Mean ROC-AUC: 0.7118\n",
      "Epoch 5/30, Train Loss: 0.2356, Val Loss: 0.2403, Mean ROC-AUC: 0.7253\n",
      "Epoch 6/30, Train Loss: 0.2346, Val Loss: 0.2327, Mean ROC-AUC: 0.7328\n",
      "Epoch 7/30, Train Loss: 0.2310, Val Loss: 0.2334, Mean ROC-AUC: 0.7338\n",
      "Epoch 8/30, Train Loss: 0.2300, Val Loss: 0.2305, Mean ROC-AUC: 0.7426\n",
      "Epoch 9/30, Train Loss: 0.2264, Val Loss: 0.2302, Mean ROC-AUC: 0.7513\n",
      "Epoch 10/30, Train Loss: 0.2248, Val Loss: 0.2330, Mean ROC-AUC: 0.7646\n",
      "Epoch 11/30, Train Loss: 0.2222, Val Loss: 0.2269, Mean ROC-AUC: 0.7640\n",
      "Epoch 12/30, Train Loss: 0.2189, Val Loss: 0.2200, Mean ROC-AUC: 0.7749\n",
      "Epoch 13/30, Train Loss: 0.2158, Val Loss: 0.2268, Mean ROC-AUC: 0.7749\n",
      "Epoch 14/30, Train Loss: 0.2159, Val Loss: 0.2293, Mean ROC-AUC: 0.7773\n",
      "Epoch 15/30, Train Loss: 0.2120, Val Loss: 0.2262, Mean ROC-AUC: 0.7827\n",
      "Epoch 16/30, Train Loss: 0.2112, Val Loss: 0.2161, Mean ROC-AUC: 0.7866\n",
      "Epoch 17/30, Train Loss: 0.2061, Val Loss: 0.2214, Mean ROC-AUC: 0.7853\n",
      "Epoch 18/30, Train Loss: 0.2066, Val Loss: 0.2174, Mean ROC-AUC: 0.7961\n",
      "Epoch 19/30, Train Loss: 0.2061, Val Loss: 0.2145, Mean ROC-AUC: 0.7888\n",
      "Epoch 20/30, Train Loss: 0.2045, Val Loss: 0.2173, Mean ROC-AUC: 0.7856\n",
      "Epoch 21/30, Train Loss: 0.2083, Val Loss: 0.2142, Mean ROC-AUC: 0.7901\n",
      "Epoch 22/30, Train Loss: 0.2020, Val Loss: 0.2122, Mean ROC-AUC: 0.7933\n",
      "Epoch 23/30, Train Loss: 0.2005, Val Loss: 0.2283, Mean ROC-AUC: 0.7873\n",
      "Epoch 24/30, Train Loss: 0.2011, Val Loss: 0.2155, Mean ROC-AUC: 0.7939\n",
      "Epoch 25/30, Train Loss: 0.2002, Val Loss: 0.2146, Mean ROC-AUC: 0.7890\n",
      "Epoch 26/30, Train Loss: 0.1982, Val Loss: 0.2102, Mean ROC-AUC: 0.8001\n",
      "Epoch 27/30, Train Loss: 0.1966, Val Loss: 0.2106, Mean ROC-AUC: 0.8011\n",
      "Epoch 28/30, Train Loss: 0.1959, Val Loss: 0.2179, Mean ROC-AUC: 0.8022\n",
      "Epoch 29/30, Train Loss: 0.1952, Val Loss: 0.2097, Mean ROC-AUC: 0.8063\n",
      "Epoch 30/30, Train Loss: 0.1934, Val Loss: 0.2111, Mean ROC-AUC: 0.8064\n",
      "\n",
      "--- Evaluating MPNN Model ---\n",
      "\n",
      "MPNN Test Metrics:\n",
      "NR-AR: ROC-AUC=0.7289, Accuracy=0.9726\n",
      "NR-AR-LBD: ROC-AUC=0.8195, Accuracy=0.9764\n",
      "NR-AhR: ROC-AUC=0.8940, Accuracy=0.9037\n",
      "NR-Aromatase: ROC-AUC=0.7616, Accuracy=0.9528\n",
      "NR-ER: ROC-AUC=0.6965, Accuracy=0.8789\n",
      "NR-ER-LBD: ROC-AUC=0.8257, Accuracy=0.9517\n",
      "NR-PPAR-gamma: ROC-AUC=0.8455, Accuracy=0.9767\n",
      "SR-ARE: ROC-AUC=0.7726, Accuracy=0.8528\n",
      "SR-ATAD5: ROC-AUC=0.8233, Accuracy=0.9692\n",
      "SR-HSE: ROC-AUC=0.7989, Accuracy=0.9547\n",
      "SR-MMP: ROC-AUC=0.8629, Accuracy=0.8736\n",
      "SR-p53: ROC-AUC=0.7723, Accuracy=0.9359\n",
      "Mean MPNN ROC-AUC: 0.8001\n",
      "\n",
      "--- Model Comparison ---\n",
      "GCN Mean ROC-AUC: 0.7638\n",
      "MPNN Mean ROC-AUC: 0.8001\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, MessagePassing\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load the Tox21 dataset\n",
    "df = pd.read_csv('tox21.csv')\n",
    "\n",
    "# Check for missing values in SMILES\n",
    "print(f\"Number of molecules with missing SMILES: {df['smiles'].isna().sum()}\")\n",
    "\n",
    "# Define the target columns\n",
    "target_columns = [\n",
    "    \"NR-AR\", \"NR-AR-LBD\", \"NR-AhR\", \"NR-Aromatase\", \"NR-ER\", \n",
    "    \"NR-ER-LBD\", \"NR-PPAR-gamma\", \"SR-ARE\", \"SR-ATAD5\", \n",
    "    \"SR-HSE\", \"SR-MMP\", \"SR-p53\"\n",
    "]\n",
    "\n",
    "# Define atom feature extraction function\n",
    "def get_atom_features(atom):\n",
    "    \"\"\"\n",
    "    Returns an array of atom features.\n",
    "    \"\"\"\n",
    "    # Atom type (one-hot encoded)\n",
    "    atom_type_one_hot = np.zeros(100)\n",
    "    atom_num = atom.GetAtomicNum()\n",
    "    if atom_num < 100:\n",
    "        atom_type_one_hot[atom_num] = 1\n",
    "    \n",
    "    # Other atom features\n",
    "    formal_charge = atom.GetFormalCharge()\n",
    "    hybridization = atom.GetHybridization()\n",
    "    is_aromatic = int(atom.GetIsAromatic())\n",
    "    num_h = atom.GetTotalNumHs()\n",
    "    \n",
    "    # Hybridization (one-hot encoded)\n",
    "    hybridization_one_hot = np.zeros(6)\n",
    "    if hybridization.name in ['S', 'SP', 'SP2', 'SP3', 'SP3D', 'SP3D2']:\n",
    "        hyb_idx = ['S', 'SP', 'SP2', 'SP3', 'SP3D', 'SP3D2'].index(hybridization.name)\n",
    "        hybridization_one_hot[hyb_idx] = 1\n",
    "    \n",
    "    # Combine all features\n",
    "    atom_features = np.concatenate([\n",
    "        atom_type_one_hot,\n",
    "        np.array([formal_charge + 4]),  # Shift +4 to ensure positive values\n",
    "        hybridization_one_hot,\n",
    "        np.array([is_aromatic]),\n",
    "        np.array([num_h])\n",
    "    ])\n",
    "    \n",
    "    return atom_features\n",
    "\n",
    "# Define bond feature extraction function\n",
    "def get_bond_features(bond):\n",
    "    \"\"\"\n",
    "    Returns an array of bond features.\n",
    "    \"\"\"\n",
    "    # Bond type (one-hot encoded)\n",
    "    bond_type_one_hot = np.zeros(4)\n",
    "    bond_type = bond.GetBondType()\n",
    "    if bond_type == Chem.rdchem.BondType.SINGLE:\n",
    "        bond_type_one_hot[0] = 1\n",
    "    elif bond_type == Chem.rdchem.BondType.DOUBLE:\n",
    "        bond_type_one_hot[1] = 1\n",
    "    elif bond_type == Chem.rdchem.BondType.TRIPLE:\n",
    "        bond_type_one_hot[2] = 1\n",
    "    elif bond_type == Chem.rdchem.BondType.AROMATIC:\n",
    "        bond_type_one_hot[3] = 1\n",
    "    \n",
    "    # Other bond features\n",
    "    is_conjugated = int(bond.GetIsConjugated())\n",
    "    is_in_ring = int(bond.IsInRing())\n",
    "    \n",
    "    # Combine all features\n",
    "    bond_features = np.concatenate([\n",
    "        bond_type_one_hot,\n",
    "        np.array([is_conjugated, is_in_ring])\n",
    "    ])\n",
    "    \n",
    "    return bond_features\n",
    "\n",
    "# Convert SMILES to molecular graphs\n",
    "def smiles_to_graph(smiles):\n",
    "    \"\"\"\n",
    "    Converts a SMILES string to a PyTorch Geometric Data object containing the molecular graph.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert SMILES to RDKit molecule\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        \n",
    "        if mol is None:\n",
    "            return None\n",
    "            \n",
    "        # Get atom features\n",
    "        atom_features_list = []\n",
    "        for atom in mol.GetAtoms():\n",
    "            atom_features_list.append(get_atom_features(atom))\n",
    "        x = torch.tensor(np.array(atom_features_list), dtype=torch.float)\n",
    "        \n",
    "        # Get edge indices and edge features\n",
    "        edge_indices = []\n",
    "        edge_features_list = []\n",
    "        \n",
    "        for bond in mol.GetBonds():\n",
    "            i = bond.GetBeginAtomIdx()\n",
    "            j = bond.GetEndAtomIdx()\n",
    "            \n",
    "            edge_indices.append([i, j])\n",
    "            edge_indices.append([j, i])  # Add reverse edge for undirected graph\n",
    "            \n",
    "            edge_features = get_bond_features(bond)\n",
    "            edge_features_list.append(edge_features)\n",
    "            edge_features_list.append(edge_features)  # Duplicate for reverse edge\n",
    "            \n",
    "        edge_index = torch.tensor(np.array(edge_indices).T, dtype=torch.long)\n",
    "        edge_attr = torch.tensor(np.array(edge_features_list), dtype=torch.float)\n",
    "        \n",
    "        # Create PyTorch Geometric Data object\n",
    "        data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error converting SMILES to graph: {e}\")\n",
    "        return None\n",
    "\n",
    "# Create a PyTorch Dataset\n",
    "class Tox21Dataset(Dataset):\n",
    "    def __init__(self, dataframe, target_columns, smiles_column='smiles'):\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.target_columns = target_columns\n",
    "        self.smiles_column = smiles_column\n",
    "        \n",
    "        # Convert SMILES to molecular graphs\n",
    "        self.graphs = []\n",
    "        self.valid_indices = []\n",
    "        \n",
    "        for idx, row in tqdm(self.dataframe.iterrows(), total=len(self.dataframe), desc=\"Converting SMILES to graphs\"):\n",
    "            graph = smiles_to_graph(row[self.smiles_column])\n",
    "            if graph is not None:\n",
    "                self.graphs.append(graph)\n",
    "                self.valid_indices.append(idx)\n",
    "        \n",
    "        # Only keep rows with valid graphs\n",
    "        self.dataframe = self.dataframe.iloc[self.valid_indices].reset_index(drop=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        graph = self.graphs[idx]\n",
    "        \n",
    "        # Get targets (handling NaN values)\n",
    "        targets = []\n",
    "        for col in self.target_columns:\n",
    "            value = self.dataframe.loc[idx, col]\n",
    "            # Convert NaN to -1 (will be masked during loss calculation)\n",
    "            targets.append(-1 if pd.isna(value) else value)\n",
    "            \n",
    "        return graph, torch.tensor(targets, dtype=torch.float)\n",
    "\n",
    "# Define Graph Convolutional Network (GCN) model\n",
    "class GCNModel(nn.Module):\n",
    "    def __init__(self, node_features, edge_features, hidden_dim, output_dim):\n",
    "        super(GCNModel, self).__init__()\n",
    "        \n",
    "        # GCN layers\n",
    "        self.conv1 = GCNConv(node_features, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = GCNConv(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # MLP for final prediction\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        # Apply GCN layers with residual connections\n",
    "        x1 = F.relu(self.conv1(x, edge_index))\n",
    "        x2 = F.relu(self.conv2(x1, edge_index)) + x1\n",
    "        x3 = F.relu(self.conv3(x2, edge_index)) + x2\n",
    "        \n",
    "        # Global pooling to get graph-level representation\n",
    "        x = global_mean_pool(x3, batch)\n",
    "        \n",
    "        # Apply MLP for final prediction\n",
    "        out = self.mlp(x)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Define Message Passing Neural Network (MPNN) model\n",
    "class MPNNLayer(MessagePassing):\n",
    "    def __init__(self, node_dim, edge_dim, hidden_dim):\n",
    "        super(MPNNLayer, self).__init__(aggr='add')\n",
    "        \n",
    "        # MLPs for message passing\n",
    "        self.message_mlp = nn.Sequential(\n",
    "            nn.Linear(node_dim + edge_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Update function\n",
    "        self.update_mlp = nn.Sequential(\n",
    "            nn.Linear(node_dim + hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # Start propagating messages\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "    \n",
    "    def message(self, x_i, x_j, edge_attr):\n",
    "        # Create messages based on source nodes and edge features\n",
    "        message_input = torch.cat([x_j, edge_attr], dim=1)\n",
    "        return self.message_mlp(message_input)\n",
    "    \n",
    "    def update(self, aggr_out, x):\n",
    "        # Update node embeddings\n",
    "        update_input = torch.cat([x, aggr_out], dim=1)\n",
    "        return self.update_mlp(update_input)\n",
    "\n",
    "class MPNNModel(nn.Module):\n",
    "    def __init__(self, node_features, edge_features, hidden_dim, output_dim):\n",
    "        super(MPNNModel, self).__init__()\n",
    "        \n",
    "        # MPNN layers\n",
    "        self.mpnn1 = MPNNLayer(node_features, edge_features, hidden_dim)\n",
    "        self.mpnn2 = MPNNLayer(hidden_dim, edge_features, hidden_dim)\n",
    "        self.mpnn3 = MPNNLayer(hidden_dim, edge_features, hidden_dim)\n",
    "        \n",
    "        # MLP for final prediction\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        \n",
    "        # Apply MPNN layers with residual connections\n",
    "        x1 = F.relu(self.mpnn1(x, edge_index, edge_attr))\n",
    "        x2 = F.relu(self.mpnn2(x1, edge_index, edge_attr)) + x1\n",
    "        x3 = F.relu(self.mpnn3(x2, edge_index, edge_attr)) + x2\n",
    "        \n",
    "        # Global pooling to get graph-level representation\n",
    "        x = global_mean_pool(x3, batch)\n",
    "        \n",
    "        # Apply MLP for final prediction\n",
    "        out = self.mlp(x)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Define a masked loss function to handle missing values\n",
    "def masked_bce_loss(pred, target):\n",
    "    # Create a mask for non-missing values (where target != -1)\n",
    "    mask = (target != -1).float()\n",
    "    \n",
    "    # Apply sigmoid to get probabilities\n",
    "    pred_probs = torch.sigmoid(pred)\n",
    "    \n",
    "    # Compute BCE loss only for non-missing values\n",
    "    loss = F.binary_cross_entropy_with_logits(pred, target * mask, reduction='none')\n",
    "    loss = loss * mask  # Zero out loss for missing values\n",
    "    \n",
    "    # Compute mean loss over non-missing values\n",
    "    non_missing = mask.sum()\n",
    "    if non_missing > 0:\n",
    "        return loss.sum() / non_missing\n",
    "    else:\n",
    "        return torch.tensor(0.0, device=pred.device)\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, optimizer, num_epochs=50, device='cuda'):\n",
    "    model.to(device)\n",
    "    best_val_roc_auc = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_roc_aucs = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for data, targets in train_loader:\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(data)\n",
    "            loss = masked_bce_loss(outputs, targets)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item() * len(targets)\n",
    "        \n",
    "        avg_train_loss = epoch_loss / len(train_loader.dataset)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        all_targets = []\n",
    "        all_outputs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, targets in val_loader:\n",
    "                data = data.to(device)\n",
    "                targets = targets.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(data)\n",
    "                loss = masked_bce_loss(outputs, targets)\n",
    "                \n",
    "                val_loss += loss.item() * len(targets)\n",
    "                \n",
    "                # Store predictions and targets for ROC-AUC calculation\n",
    "                # Only store non-missing values\n",
    "                mask = (targets != -1).cpu().numpy()\n",
    "                all_targets.append(targets.cpu().numpy())\n",
    "                all_outputs.append(outputs.cpu().numpy())\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        # Compute ROC-AUC for each task\n",
    "        all_targets = np.vstack(all_targets)\n",
    "        all_outputs = np.vstack(all_outputs)\n",
    "        \n",
    "        task_roc_aucs = []\n",
    "        for task_idx in range(len(target_columns)):\n",
    "            # Get mask for non-missing values\n",
    "            mask = (all_targets[:, task_idx] != -1)\n",
    "            if mask.sum() > 0 and len(np.unique(all_targets[mask, task_idx])) > 1:\n",
    "                y_true = all_targets[mask, task_idx]\n",
    "                y_score = all_outputs[mask, task_idx]\n",
    "                try:\n",
    "                    roc_auc = roc_auc_score(y_true, y_score)\n",
    "                    task_roc_aucs.append(roc_auc)\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        if task_roc_aucs:\n",
    "            mean_roc_auc = np.mean(task_roc_aucs)\n",
    "            val_roc_aucs.append(mean_roc_auc)\n",
    "            \n",
    "            # Save best model\n",
    "            if mean_roc_auc > best_val_roc_auc:\n",
    "                best_val_roc_auc = mean_roc_auc\n",
    "                best_model_state = model.state_dict().copy()\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Mean ROC-AUC: {mean_roc_auc:.4f}\")\n",
    "        else:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Mean ROC-AUC: N/A\")\n",
    "    \n",
    "    # Load best model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    return model, train_losses, val_losses, val_roc_aucs\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, test_loader, device='cuda'):\n",
    "    model.eval()\n",
    "    all_targets = []\n",
    "    all_outputs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            data = data.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(data)\n",
    "            \n",
    "            # Store predictions and targets\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "            all_outputs.append(outputs.cpu().numpy())\n",
    "    \n",
    "    all_targets = np.vstack(all_targets)\n",
    "    all_outputs = np.vstack(all_outputs)\n",
    "    \n",
    "    # Compute metrics for each task\n",
    "    task_metrics = {}\n",
    "    for task_idx, task_name in enumerate(target_columns):\n",
    "        # Get mask for non-missing values\n",
    "        mask = (all_targets[:, task_idx] != -1)\n",
    "        if mask.sum() > 0 and len(np.unique(all_targets[mask, task_idx])) > 1:\n",
    "            y_true = all_targets[mask, task_idx]\n",
    "            y_score = all_outputs[mask, task_idx]\n",
    "            y_pred = (y_score > 0).astype(int)  # Threshold at 0 (sigmoid=0.5)\n",
    "            \n",
    "            try:\n",
    "                task_roc_auc = roc_auc_score(y_true, y_score)\n",
    "                task_accuracy = accuracy_score(y_true, y_pred)\n",
    "                \n",
    "                task_metrics[task_name] = {\n",
    "                    'roc_auc': task_roc_auc,\n",
    "                    'accuracy': task_accuracy\n",
    "                }\n",
    "            except:\n",
    "                task_metrics[task_name] = {\n",
    "                    'roc_auc': np.nan,\n",
    "                    'accuracy': np.nan\n",
    "                }\n",
    "    \n",
    "    return task_metrics\n",
    "\n",
    "# Main function to run the full pipeline\n",
    "def main():\n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    df = pd.read_csv('tox21.csv')\n",
    "    \n",
    "    # Split data into train, validation, and test sets (64%, 16%, 20%)\n",
    "    train_df, temp_df = train_test_split(df, test_size=0.36, random_state=42)  # 64% for training\n",
    "    val_df, test_df = train_test_split(temp_df, test_size=0.5556, random_state=42)  # 16% for validation, 20% for testing\n",
    "    \n",
    "    print(f\"Train set size: {len(train_df)}\")\n",
    "    print(f\"Validation set size: {len(val_df)}\")\n",
    "    print(f\"Test set size: {len(test_df)}\")\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = Tox21Dataset(train_df, target_columns)\n",
    "    val_dataset = Tox21Dataset(val_df, target_columns)\n",
    "    test_dataset = Tox21Dataset(test_df, target_columns)\n",
    "    \n",
    "    print(f\"Train dataset size after processing: {len(train_dataset)}\")\n",
    "    print(f\"Validation dataset size after processing: {len(val_dataset)}\")\n",
    "    print(f\"Test dataset size after processing: {len(test_dataset)}\")\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=Batch.from_data_list)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=Batch.from_data_list)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=Batch.from_data_list)\n",
    "    \n",
    "    # Get dimensions for model initialization\n",
    "    sample_graph = train_dataset[0][0]\n",
    "    node_features = sample_graph.x.size(1)\n",
    "    edge_features = sample_graph.edge_attr.size(1)\n",
    "    output_dim = len(target_columns)\n",
    "    \n",
    "    print(f\"Node feature dimension: {node_features}\")\n",
    "    print(f\"Edge feature dimension: {edge_features}\")\n",
    "    print(f\"Output dimension: {output_dim}\")\n",
    "    \n",
    "    # Initialize models\n",
    "    gcn_model = GCNModel(node_features, edge_features, hidden_dim=64, output_dim=output_dim)\n",
    "    mpnn_model = MPNNModel(node_features, edge_features, hidden_dim=64, output_dim=output_dim)\n",
    "    \n",
    "    # Train and evaluate GCN model\n",
    "    print(\"\\n--- Training GCN Model ---\")\n",
    "    gcn_optimizer = torch.optim.Adam(gcn_model.parameters(), lr=0.001)\n",
    "    gcn_model, gcn_train_losses, gcn_val_losses, gcn_val_roc_aucs = train_model(\n",
    "        gcn_model, train_loader, val_loader, gcn_optimizer, num_epochs=30, device=device\n",
    "    )\n",
    "    \n",
    "    # Evaluate GCN model on test set\n",
    "    print(\"\\n--- Evaluating GCN Model ---\")\n",
    "    gcn_metrics = evaluate_model(gcn_model, test_loader, device=device)\n",
    "    \n",
    "    # Print GCN metrics\n",
    "    print(\"\\nGCN Test Metrics:\")\n",
    "    gcn_roc_aucs = []\n",
    "    for task, metrics in gcn_metrics.items():\n",
    "        print(f\"{task}: ROC-AUC={metrics['roc_auc']:.4f}, Accuracy={metrics['accuracy']:.4f}\")\n",
    "        gcn_roc_aucs.append(metrics['roc_auc'])\n",
    "    \n",
    "    print(f\"Mean GCN ROC-AUC: {np.nanmean(gcn_roc_aucs):.4f}\")\n",
    "    \n",
    "    # Train and evaluate MPNN model\n",
    "    print(\"\\n--- Training MPNN Model ---\")\n",
    "    mpnn_optimizer = torch.optim.Adam(mpnn_model.parameters(), lr=0.001)\n",
    "    mpnn_model, mpnn_train_losses, mpnn_val_losses, mpnn_val_roc_aucs = train_model(\n",
    "        mpnn_model, train_loader, val_loader, mpnn_optimizer, num_epochs=30, device=device\n",
    "    )\n",
    "    \n",
    "    # Evaluate MPNN model on test set\n",
    "    print(\"\\n--- Evaluating MPNN Model ---\")\n",
    "    mpnn_metrics = evaluate_model(mpnn_model, test_loader, device=device)\n",
    "    \n",
    "    # Print MPNN metrics\n",
    "    print(\"\\nMPNN Test Metrics:\")\n",
    "    mpnn_roc_aucs = []\n",
    "    for task, metrics in mpnn_metrics.items():\n",
    "        print(f\"{task}: ROC-AUC={metrics['roc_auc']:.4f}, Accuracy={metrics['accuracy']:.4f}\")\n",
    "        mpnn_roc_aucs.append(metrics['roc_auc'])\n",
    "    \n",
    "    print(f\"Mean MPNN ROC-AUC: {np.nanmean(mpnn_roc_aucs):.4f}\")\n",
    "    \n",
    "    # Compare GCN and MPNN results\n",
    "    print(\"\\n--- Model Comparison ---\")\n",
    "    print(f\"GCN Mean ROC-AUC: {np.nanmean(gcn_roc_aucs):.4f}\")\n",
    "    print(f\"MPNN Mean ROC-AUC: {np.nanmean(mpnn_roc_aucs):.4f}\")\n",
    "    \n",
    "    # Plot training curves\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(gcn_train_losses, label='GCN Train Loss')\n",
    "    plt.plot(gcn_val_losses, label='GCN Val Loss')\n",
    "    plt.plot(mpnn_train_losses, label='MPNN Train Loss')\n",
    "    plt.plot(mpnn_val_losses, label='MPNN Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Loss')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(gcn_val_roc_aucs, label='GCN ROC-AUC')\n",
    "    plt.plot(mpnn_val_roc_aucs, label='MPNN ROC-AUC')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('ROC-AUC')\n",
    "    plt.legend()\n",
    "    plt.title('Validation ROC-AUC')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('gnn_training_curves.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Create performance comparison bar chart\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Get data for plotting\n",
    "    tasks = list(gcn_metrics.keys())\n",
    "    gcn_scores = [metrics['roc_auc'] for metrics in gcn_metrics.values()]\n",
    "    mpnn_scores = [metrics['roc_auc'] for metrics in mpnn_metrics.values()]\n",
    "    \n",
    "    x = np.arange(len(tasks))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.bar(x - width/2, gcn_scores, width, label='GCN')\n",
    "    plt.bar(x + width/2, mpnn_scores, width, label='MPNN')\n",
    "    \n",
    "    plt.xlabel('Target')\n",
    "    plt.ylabel('ROC-AUC')\n",
    "    plt.title('Model Performance Comparison')\n",
    "    plt.xticks(x, tasks, rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('gnn_performance_comparison.png')\n",
    "    plt.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f35e3c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSS5104",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
